{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base class for Gates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Define the base class for Gates \n",
    "class Gate: \n",
    "    def forward(self): \n",
    "        raise NotImplementedError \n",
    "    def backward(self): \n",
    "        raise NotImplementedError  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AddGate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of an AddGate class inheriting from the Gate class \n",
    "class AddGate(Gate): \n",
    "    def forward(self, x, y): \n",
    "        self.x = x \n",
    "        self.y = y \n",
    "        return x + y \n",
    "    def backward(self, dz): \n",
    "        dx = dz * np.ones_like(self.x) \n",
    "        dy = dz * np.ones_like(self.y) \n",
    "        return dx, dy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " MultiplyGate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a MultiplyGate class inheriting from the Gate class\n",
    "class MultiplyGate(Gate):\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        return np.matmul(x,y)\n",
    "\n",
    "    def backward(self, dz,ax):\n",
    "        dx = np.matmul(dz,ax)\n",
    "        dy = dz * self.x.T\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example of a Linear activation function\n",
    "class LinearActivation(Gate):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return x\n",
    "\n",
    "    def backward(self, dz):\n",
    "        dx = dz\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a ReLU activation function\n",
    "class ReLUActivation(Gate):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, dz):\n",
    "        dx = dz * np.where(self.x > 0, 1, 0)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# class SigmoidActivation:\n",
    "#     def __init__(self):\n",
    "#         self.x = None\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         self.x = x\n",
    "#         return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#     def backward(self, dz):\n",
    "#         sigmoid_x = 1 / (1 + np.exp(-self.x))\n",
    "#         dx = dz * sigmoid_x * (1 - sigmoid_x)\n",
    "#         return dx\n",
    "class SigmoidActivation:\n",
    "    def __init__(self):\n",
    "        self.sigmoid_x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.sigmoid_x = 1 / (1 + np.exp(-x))\n",
    "        return self.sigmoid_x\n",
    "\n",
    "    def backward(self, dz):\n",
    "        if self.sigmoid_x is None:\n",
    "            raise ValueError(\"Forward method must be called before backward method.\")\n",
    "        dx = dz * self.sigmoid_x * (1 - self.sigmoid_x)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a Softmax activation function\n",
    "class SoftmaxActivation(Gate):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "    def backward(self, dz):\n",
    "        softmax_x = self.forward(self.x)\n",
    "        dx = dz * softmax_x * (1 - softmax_x)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanh activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a Tanh activation function\n",
    "class TanhActivation(Gate):\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def backward(self, dz):\n",
    "        tanh_x = np.tanh(self.x)\n",
    "        dx = dz * (1 - tanh_x ** 2)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Binary Cross-Entropy (BCE) loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Binary Cross-Entropy (BCE) loss function\n",
    "class BinaryCrossEntropyLoss(Gate):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "    def backward(self):\n",
    "        dx = (self.y_pred - self.y_true) / (self.y_pred * (1 - self.y_pred))\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of L2 loss function\n",
    "class L2Loss(Gate):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "        return 0.5 * np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def backward(self):\n",
    "        dx = self.y_pred - self.y_true\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Computational Graph / Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers_dim, activation_func, loss):\n",
    "        self.layers_dim = layers_dim\n",
    "        self.activation_func = activation_func\n",
    "        self.loss = loss\n",
    "        self.parameters = {}\n",
    "        self.activations = {}\n",
    "        self.gradients = {}\n",
    "        self.add = AddGate()\n",
    "        self.multiply = MultiplyGate()\n",
    "\n",
    "        # Initialize weights and biases using Xavier initialization\n",
    "        for i in range(1, len(layers_dim)):\n",
    "            prev_dim = layers_dim[i - 1]\n",
    "            curr_dim = layers_dim[i]\n",
    "            self.parameters[\"W\" + str(i)] = np.random.randn(curr_dim, prev_dim) * np.sqrt(1 / prev_dim)\n",
    "            self.parameters[\"b\" + str(i)] = np.zeros((curr_dim, 1))  # Initialize biases as column vectors\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.activations[\"A0\"] = X\n",
    "\n",
    "        for i in range(1, len(self.layers_dim)):\n",
    "            prev_a = self.activations[\"A\" + str(i - 1)]\n",
    "            W = self.parameters[\"W\" + str(i)]\n",
    "            b = self.parameters[\"b\" + str(i)]\n",
    "\n",
    "            activation_func = self.activation_func()  # Create an instance of the activation function\n",
    "            print(f\"w:{W}\")\n",
    "            print(f\"a:{prev_a}\")\n",
    "            Z = self.add.forward(self.multiply.forward(W, prev_a) , b)\n",
    "            A = activation_func.forward(Z)\n",
    "\n",
    "            self.activations[\"A\" + str(i)] = A\n",
    "            self.activations[\"Z\" + str(i)] = Z\n",
    "\n",
    "        return self.activations[\"A\" + str(len(self.layers_dim) - 1)]\n",
    "\n",
    "    def train(self, X, y, num_epochs, learning_rate, batch_size=None,mode='batch',):\n",
    "        m = X.shape[1]  \n",
    "        for epoch in range(num_epochs):\n",
    "            if mode == 'batch':\n",
    "                X, y = X, y  \n",
    "            elif mode == 'stochastic':\n",
    "                idx = np.random.choice(m, size=1, replace=False)  \n",
    "                X, y = X[:, idx], y[:, idx]\n",
    "            elif mode == 'mini-batch':\n",
    "                idx = np.random.choice(m, size=batch_size, replace=False)  \n",
    "                X, y = X[:,idx],y[:,idx]\n",
    "            # Forward propagation\n",
    "            A = self.predict(X)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = self.loss.forward(A, y)\n",
    "            mse = np.mean((A - y) ** 2)\n",
    "\n",
    "            # Backward propagation\n",
    "            dA = self.loss.backward()\n",
    "            self.gradients[\"dA\" + str(len(self.layers_dim) - 1)] = dA\n",
    "\n",
    "            for i in reversed(range(1, len(self.layers_dim))):\n",
    "                activation_func = self.activation_func()  # Create an instance of the activation function\n",
    "                A_prev = self.activations[\"A\" + str(i - 1)]\n",
    "                W = self.parameters[\"W\" + str(i)]\n",
    "                b = self.parameters[\"b\" + str(i)]\n",
    "\n",
    "                Z = self.activations[\"Z\" + str(i)]  # Retrieve Z from stored activations\n",
    "                activation_func.forward(Z)  # Call forward method to compute self.sigmoid_x\n",
    "                dZ = activation_func.backward(self.gradients[\"dA\" + str(i)])  # Pass Z to backward method\n",
    "                dt,db = self.add.backward(dZ)\n",
    "                dW,dx= self.multiply.backward(dt,A_prev.T)\n",
    "                #dW = np.dot(dZ, A_prev.T)\n",
    "                db = np.sum(db, axis=1, keepdims=True)\n",
    "\n",
    "                self.gradients[\"dA\" + str(i - 1)] = np.dot(W.T, dZ)\n",
    "                self.gradients[\"dW\" + str(i)] = dW\n",
    "                self.gradients[\"db\" + str(i)] = db\n",
    "\n",
    "            # Update parameters\n",
    "            for i in range(1, len(self.layers_dim)):\n",
    "                self.parameters[\"W\" + str(i)] -= learning_rate * self.gradients[\"dW\" + str(i)]\n",
    "                self.parameters[\"b\" + str(i)] -= learning_rate * self.gradients[\"db\" + str(i)]\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss}, MSE: {mse}\")\n",
    "            print(\"Weights:\")\n",
    "            for i in range(1, len(self.layers_dim)):\n",
    "                print(f\"Layer {i}:\")\n",
    "                print(f\"W{i}:\")\n",
    "                print(self.parameters[\"W\" + str(i)])\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Example usage\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:[[ 0.70017173 -0.35859011]\n",
      " [ 0.35596178  0.07110566]\n",
      " [-0.64246868  1.00927235]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.11879277  0.67703981  0.41030135]]\n",
      "a:[[0.5        0.4113009  0.66822585 0.58457466]\n",
      " [0.5        0.51776893 0.58806255 0.60517318]\n",
      " [0.5        0.73287772 0.34468871 0.59068641]]\n",
      "Epoch 1/100, Loss: 0.13368783064872272, MSE: 0.26737566129744544\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70035561 -0.35839714]\n",
      " [ 0.35508046  0.07008627]\n",
      " [-0.64308159  1.00845846]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.1252552   0.67039885  0.40338015]]\n",
      "\n",
      "w:[[ 0.70035561 -0.35839714]\n",
      " [ 0.35508046  0.07008627]\n",
      " [-0.64308159  1.00845846]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.1252552   0.67039885  0.40338015]]\n",
      "a:[[0.50009618 0.41144079 0.66835189 0.5847596 ]\n",
      " [0.49950387 0.51701886 0.58736813 0.60424447]\n",
      " [0.49963489 0.73243225 0.34422053 0.58998816]]\n",
      "Epoch 2/100, Loss: 0.13297882823513915, MSE: 0.2659576564702783\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70054357 -0.35820022]\n",
      " [ 0.35424076  0.06911051]\n",
      " [-0.64366608  1.00767563]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.13148133  0.66400977  0.39670516]]\n",
      "\n",
      "w:[[ 0.70054357 -0.35820022]\n",
      " [ 0.35424076  0.06911051]\n",
      " [-0.64366608  1.00767563]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.13148133  0.66400977  0.39670516]]\n",
      "a:[[0.50019432 0.41158355 0.66848056 0.58494837]\n",
      " [0.4990306  0.51630245 0.58670564 0.6033573 ]\n",
      " [0.4992855  0.73200473 0.34377325 0.58931916]]\n",
      "Epoch 3/100, Loss: 0.1323214176557028, MSE: 0.2646428353114056\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70073469 -0.35800034]\n",
      " [ 0.35344145  0.06817724]\n",
      " [-0.64422324  1.00692281]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.13747396  0.65786873  0.39027309]]\n",
      "\n",
      "w:[[ 0.70073469 -0.35800034]\n",
      " [ 0.35344145  0.06817724]\n",
      " [-0.64422324  1.00692281]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.13747396  0.65786873  0.39027309]]\n",
      "a:[[0.50029396 0.41172848 0.66861123 0.58514004]\n",
      " [0.49857948 0.51561871 0.58607413 0.60251051]\n",
      " [0.49895121 0.73159452 0.34334603 0.58867834]]\n",
      "Epoch 4/100, Loss: 0.13171295528071356, MSE: 0.2634259105614271\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70092813 -0.35779842]\n",
      " [ 0.35268126  0.06728519]\n",
      " [-0.64475418  1.00619893]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.14323659  0.6519712   0.38407997]]\n",
      "\n",
      "w:[[ 0.70092813 -0.35779842]\n",
      " [ 0.35268126  0.06728519]\n",
      " [-0.64475418  1.00619893]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.14323659  0.6519712   0.38407997]]\n",
      "a:[[0.50039464 0.41187494 0.66874331 0.58533377]\n",
      " [0.49814976 0.51496657 0.58547259 0.60170286]\n",
      " [0.49863139 0.731201   0.34293802 0.58806461]]\n",
      "Epoch 5/100, Loss: 0.13115075195638365, MSE: 0.2623015039127673\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70112314 -0.35759532]\n",
      " [ 0.35195886  0.06643306]\n",
      " [-0.64526     1.0055029 ]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.14877333  0.64631211  0.37812122]]\n",
      "\n",
      "w:[[ 0.70112314 -0.35759532]\n",
      " [ 0.35195886  0.06643306]\n",
      " [-0.64526     1.0055029 ]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.14877333  0.64631211  0.37812122]]\n",
      "a:[[0.50049597 0.41202233 0.66887628 0.58552876]\n",
      " [0.49774066 0.51434497 0.5849     0.60093309]\n",
      " [0.49832545 0.73082349 0.34254839 0.58747688]]\n",
      "Epoch 6/100, Loss: 0.13063210916216378, MSE: 0.26126421832432756\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.701319   -0.35739181]\n",
      " [ 0.35127288  0.0656195 ]\n",
      " [-0.64574183  1.0048336 ]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.1540888   0.64088588  0.37239174]]\n",
      "\n",
      "w:[[ 0.701319   -0.35739181]\n",
      " [ 0.35127288  0.0656195 ]\n",
      " [-0.64574183  1.0048336 ]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.1540888   0.64088588  0.37239174]]\n",
      "a:[[0.50059757 0.41217009 0.66900965 0.58572429]\n",
      " [0.49735141 0.51375279 0.58435531 0.60019985]\n",
      " [0.49803274 0.73046135 0.34217629 0.58691405]]\n",
      "Epoch 7/100, Loss: 0.1301543500435429, MSE: 0.2603087000870858\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70151508 -0.35718859]\n",
      " [ 0.35062196  0.06484313]\n",
      " [-0.64620077  1.00418991]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.15918808  0.63568655  0.36688602]]\n",
      "\n",
      "w:[[ 0.70151508 -0.35718859]\n",
      " [ 0.35062196  0.06484313]\n",
      " [-0.64620077  1.00418991]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.15918808  0.63568655  0.36688602]]\n",
      "a:[[0.50069911 0.41231774 0.669143   0.58591972]\n",
      " [0.49698122 0.5131889  0.58383745 0.59950183]\n",
      " [0.49775267 0.7301139  0.3418209  0.586375  ]]\n",
      "Epoch 8/100, Loss: 0.12971484544539807, MSE: 0.25942969089079615\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70171081 -0.35698629]\n",
      " [ 0.3500047   0.06410255]\n",
      " [-0.64663791  1.00357072]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.1640766   0.63070784  0.36159818]]\n",
      "\n",
      "w:[[ 0.70171081 -0.35698629]\n",
      " [ 0.3500047   0.06410255]\n",
      " [-0.64663791  1.00357072]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.1640766   0.63070784  0.36159818]]\n",
      "a:[[0.50080029 0.41246484 0.66927592 0.58611448]\n",
      " [0.49662932 0.5126522  0.58334537 0.59883765]\n",
      " [0.49748464 0.72978049 0.34148142 0.58585866]]\n",
      "Epoch 9/100, Loss: 0.12931103520462367, MSE: 0.25862207040924734\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70190569 -0.35678548]\n",
      " [ 0.34941974  0.06339637]\n",
      " [-0.64705432  1.00297494]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.16876006  0.62594323  0.35652208]]\n",
      "\n",
      "w:[[ 0.70190569 -0.35678548]\n",
      " [ 0.34941974  0.06339637]\n",
      " [-0.64705432  1.00297494]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.16876006  0.62594323  0.35652208]]\n",
      "a:[[0.50090085 0.41261099 0.66940808 0.58630803]\n",
      " [0.49629493 0.51214157 0.58287801 0.59820598]\n",
      " [0.49722805 0.72946049 0.34115706 0.58536397]]\n",
      "Epoch 10/100, Loss: 0.12894044505516916, MSE: 0.2578808901103383\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70209925 -0.35658665]\n",
      " [ 0.3488657   0.0627232 ]\n",
      " [-0.64745104  1.0024015 ]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.17324442  0.62138602  0.35165137]]\n",
      "\n",
      "w:[[ 0.70209925 -0.35658665]\n",
      " [ 0.3488657   0.0627232 ]\n",
      " [-0.64745104  1.0024015 ]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.17324442  0.62138602  0.35165137]]\n",
      "a:[[0.50100056 0.41275585 0.66953916 0.58649992]\n",
      " [0.49597729 0.51165589 0.5824343  0.59760546]\n",
      " [0.49698235 0.72915324 0.34084704 0.58488987]]\n",
      "Epoch 11/100, Loss: 0.12860069955854503, MSE: 0.25720139911709006\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70229112 -0.35639024]\n",
      " [ 0.34834124  0.06208166]\n",
      " [-0.64782906  1.00184933]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.17753578  0.61702941  0.34697955]]\n",
      "\n",
      "w:[[ 0.70229112 -0.35639024]\n",
      " [ 0.34834124  0.06208166]\n",
      " [-0.64782906  1.00184933]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.17753578  0.61702941  0.34697955]]\n",
      "a:[[0.5010992  0.4128991  0.6696689  0.58668976]\n",
      " [0.49567565 0.51119409 0.58201324 0.59703477]\n",
      " [0.49674697 0.72885815 0.34055063 0.58443535]]\n",
      "Epoch 12/100, Loss: 0.12828953150384648, MSE: 0.25657906300769295\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70248094 -0.35619663]\n",
      " [ 0.34784506  0.06147038]\n",
      " [-0.64818937  1.00131742]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.18164035  0.61286653  0.34250004]]\n",
      "\n",
      "w:[[ 0.70248094 -0.35619663]\n",
      " [ 0.34784506  0.06147038]\n",
      " [-0.64818937  1.00131742]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.18164035  0.61286653  0.34250004]]\n",
      "a:[[0.5011966  0.41304049 0.66979707 0.58687721]\n",
      " [0.49538929 0.5107551  0.5816138  0.59649262]\n",
      " [0.49652139 0.72857461 0.34026712 0.58399943]]\n",
      "Epoch 13/100, Loss: 0.1280047882291205, MSE: 0.256009576458241\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70266843 -0.35600614]\n",
      " [ 0.34737586  0.06088805]\n",
      " [-0.64853291  1.00080478]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.18556441  0.60889047  0.33820621]]\n",
      "\n",
      "w:[[ 0.70266843 -0.35600614]\n",
      " [ 0.34737586  0.06088805]\n",
      " [-0.64853291  1.00080478]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.18556441  0.60889047  0.33820621]]\n",
      "a:[[0.50129262 0.41317979 0.66992347 0.58706195]\n",
      " [0.4951175  0.51033788 0.58123499 0.59597772]\n",
      " [0.49630509 0.72830204 0.33999582 0.58358116]]\n",
      "Epoch 14/100, Loss: 0.1277444353059059, MSE: 0.2554888706118118\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70285332 -0.35581905]\n",
      " [ 0.34693239  0.06033337]\n",
      " [-0.64886056  1.00031043]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.18931427  0.60509439  0.33409142]]\n",
      "\n",
      "w:[[ 0.70285332 -0.35581905]\n",
      " [ 0.34693239  0.06033337]\n",
      " [-0.64886056  1.00031043]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.18931427  0.60509439  0.33409142]]\n",
      "a:[[0.50138712 0.41331682 0.67004793 0.58724375]\n",
      " [0.49485958 0.50994143 0.58087587 0.59548884]\n",
      " [0.49609758 0.72803989 0.33973608 0.58317963]]\n",
      "Epoch 15/100, Loss: 0.12750655800593863, MSE: 0.25501311601187726\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70303542 -0.35563559]\n",
      " [ 0.34651344  0.05980507]\n",
      " [-0.64917319  0.99983348]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.1928962   0.60147146  0.33014907]]\n",
      "\n",
      "w:[[ 0.70303542 -0.35563559]\n",
      " [ 0.34651344  0.05980507]\n",
      " [-0.64917319  0.99983348]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.1928962   0.60147146  0.33014907]]\n",
      "a:[[0.50148    0.4134514  0.67017031 0.5874224 ]\n",
      " [0.49461487 0.50956477 0.58053551 0.59502478]\n",
      " [0.4958984  0.72778762 0.33948726 0.58279396]]\n",
      "Epoch 16/100, Loss: 0.12728936093755563, MSE: 0.25457872187511127\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70321454 -0.35545593]\n",
      " [ 0.34611785  0.05930195]\n",
      " [-0.64947163  0.99937302]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.19631644  0.59801498  0.32637265]]\n",
      "\n",
      "w:[[ 0.70321454 -0.35545593]\n",
      " [ 0.34611785  0.05930195]\n",
      " [-0.64947163  0.99937302]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.19631644  0.59801498  0.32637265]]\n",
      "a:[[0.50157117 0.41358341 0.67029051 0.58759773]\n",
      " [0.49438274 0.50920695 0.58021301 0.59458437]\n",
      " [0.49570709 0.72754471 0.33924878 0.58242331]]\n",
      "Epoch 17/100, Loss: 0.12709116620274588, MSE: 0.25418233240549176\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70339056 -0.35528024]\n",
      " [ 0.34574449  0.0588228 ]\n",
      " [-0.64975665  0.99892821]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.19958115  0.59471834  0.32275571]]\n",
      "\n",
      "w:[[ 0.70339056 -0.35528024]\n",
      " [ 0.34574449  0.0588228 ]\n",
      " [-0.64975665  0.99892821]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.19958115  0.59471834  0.32275571]]\n",
      "a:[[0.50166057 0.41371276 0.67040842 0.5877696 ]\n",
      " [0.49416257 0.50886708 0.57990751 0.59416648]\n",
      " [0.49552323 0.72731069 0.33902006 0.58206689]]\n",
      "Epoch 18/100, Loss: 0.12691041038685236, MSE: 0.2538208207737047\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70356337 -0.35510863]\n",
      " [ 0.34539227  0.05836651]\n",
      " [-0.650029    0.99849824]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.20269639  0.59157507  0.31929192]]\n",
      "\n",
      "w:[[ 0.70356337 -0.35510863]\n",
      " [ 0.34539227  0.05836651]\n",
      " [-0.650029    0.99849824]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.20269639  0.59157507  0.31929192]]\n",
      "a:[[0.50174814 0.41383935 0.67052399 0.58793791]\n",
      " [0.49395377 0.50854427 0.57961818 0.59377003]\n",
      " [0.4953464  0.72708506 0.33880055 0.58172393]]\n",
      "Epoch 19/100, Loss: 0.1267456406537219, MSE: 0.2534912813074438\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70373288 -0.35494117]\n",
      " [ 0.34506016  0.05793197]\n",
      " [-0.65028939  0.99808234]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.2056681   0.58857884  0.31597511]]\n",
      "\n",
      "w:[[ 0.70373288 -0.35494117]\n",
      " [ 0.34506016  0.05793197]\n",
      " [-0.65028939  0.99808234]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.2056681   0.58857884  0.31597511]]\n",
      "a:[[0.50183384 0.41396313 0.67063716 0.58810259]\n",
      " [0.49375577 0.50823769 0.57934422 0.59339399]\n",
      " [0.49517624 0.7268674  0.33858976 0.5813937 ]]\n",
      "Epoch 20/100, Loss: 0.12659551018115806, MSE: 0.2531910203623161\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70389903 -0.35477792]\n",
      " [ 0.34474716  0.05751814]\n",
      " [-0.65053849  0.99767977]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.2085021   0.58572351  0.31279923]]\n",
      "\n",
      "w:[[ 0.70389903 -0.35477792]\n",
      " [ 0.34474716  0.05751814]\n",
      " [-0.65053849  0.99767977]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.2085021   0.58572351  0.31279923]]\n",
      "a:[[0.50191764 0.41408407 0.6707479  0.58826358]\n",
      " [0.49356803 0.50794654 0.57908488 0.59303736]\n",
      " [0.49501236 0.72665728 0.33838719 0.58107552]]\n",
      "Epoch 21/100, Loss: 0.1264587731358878, MSE: 0.2529175462717756\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7040618  -0.35461892]\n",
      " [ 0.34445231  0.057124  ]\n",
      " [-0.65077693  0.99728982]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.21120406  0.58300308  0.3097584 ]]\n",
      "\n",
      "w:[[ 0.7040618  -0.35461892]\n",
      " [ 0.34445231  0.057124  ]\n",
      " [-0.65077693  0.99728982]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.21120406  0.58300308  0.3097584 ]]\n",
      "a:[[0.50199954 0.41420213 0.67085619 0.58842086]\n",
      " [0.49339004 0.50767005 0.57883942 0.59269917]\n",
      " [0.49485442 0.72645428 0.33819239 0.58076872]]\n",
      "Epoch 22/100, Loss: 0.12633427935455455, MSE: 0.2526685587091091\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70422117 -0.35446418]\n",
      " [ 0.34417471  0.05674859]\n",
      " [-0.65100531  0.99691184]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.2137795   0.58041176  0.30684691]]\n",
      "\n",
      "w:[[ 0.70422117 -0.35446418]\n",
      " [ 0.34417471  0.05674859]\n",
      " [-0.65100531  0.99691184]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.2137795   0.58041176  0.30684691]]\n",
      "a:[[0.50207954 0.41431732 0.67096202 0.58857441]\n",
      " [0.4932213  0.50740749 0.57860716 0.59237852]\n",
      " [0.4947021  0.72625804 0.33800491 0.58047269]]\n",
      "Epoch 23/100, Loss: 0.1262209688678338, MSE: 0.2524419377356676\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70437715 -0.35431368]\n",
      " [ 0.34391349  0.05639099]\n",
      " [-0.6512242   0.99654519]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.21623377  0.57794393  0.30405921]]\n",
      "\n",
      "w:[[ 0.70437715 -0.35431368]\n",
      " [ 0.34391349  0.05639099]\n",
      " [-0.6512242   0.99654519]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.21623377  0.57794393  0.30405921]]\n",
      "a:[[0.50215762 0.41442964 0.67106541 0.58872426]\n",
      " [0.49306134 0.50715815 0.57838742 0.59207454]\n",
      " [0.49455508 0.72606818 0.33782436 0.58018685]]\n",
      "Epoch 24/100, Loss: 0.12611786637874883, MSE: 0.25223573275749767\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70452973 -0.3541674 ]\n",
      " [ 0.34366782  0.05605033]\n",
      " [-0.65143414  0.99618927]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.21857206  0.57559416  0.30138996]]\n",
      "\n",
      "w:[[ 0.70452973 -0.3541674 ]\n",
      " [ 0.34366782  0.05605033]\n",
      " [-0.65143414  0.99618927]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.21857206  0.57559416  0.30138996]]\n",
      "a:[[0.50223382 0.41453911 0.67116636 0.58887041]\n",
      " [0.49290972 0.50692138 0.57817957 0.59178638]\n",
      " [0.49441308 0.72588436 0.33765034 0.57991063]]\n",
      "Epoch 25/100, Loss: 0.12602407578358515, MSE: 0.2520481515671703\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70467897 -0.3540253 ]\n",
      " [ 0.34343691  0.05572575]\n",
      " [-0.65163563  0.99584352]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.22079939  0.57335723  0.29883397]]\n",
      "\n",
      "w:[[ 0.70467897 -0.3540253 ]\n",
      " [ 0.34343691  0.05572575]\n",
      " [-0.65163563  0.99584352]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.22079939  0.57335723  0.29883397]]\n",
      "a:[[0.50230814 0.41464575 0.6712649  0.58901291]\n",
      " [0.49276601 0.50669654 0.57798302 0.59151327]\n",
      " [0.49427581 0.72570626 0.33748248 0.5796435 ]]\n",
      "Epoch 26/100, Loss: 0.125938774804301, MSE: 0.251877549608602\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70482489 -0.35388732]\n",
      " [ 0.34322001  0.05541646]\n",
      " [-0.65182916  0.99550739]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.22292061  0.57122808  0.29638626]]\n",
      "\n",
      "w:[[ 0.70482489 -0.35388732]\n",
      " [ 0.34322001  0.05541646]\n",
      " [-0.65182916  0.99550739]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.22292061  0.57122808  0.29638626]]\n",
      "a:[[0.50238062 0.41474961 0.67136107 0.58915181]\n",
      " [0.49262981 0.50648303 0.57779718 0.59125443]\n",
      " [0.49414301 0.72553356 0.33732044 0.57938498]]\n",
      "Epoch 27/100, Loss: 0.12586120978476906, MSE: 0.2517224195695381\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70496755 -0.3537534 ]\n",
      " [ 0.34301642  0.0551217 ]\n",
      " [-0.65201517  0.99518038]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.2249404   0.56920186  0.294042  ]]\n",
      "\n",
      "w:[[ 0.70496755 -0.3537534 ]\n",
      " [ 0.34301642  0.0551217 ]\n",
      " [-0.65201517  0.99518038]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.2249404   0.56920186  0.294042  ]]\n",
      "a:[[0.50245127 0.41485073 0.6714549  0.58928716]\n",
      " [0.49250073 0.50628026 0.57762152 0.59100916]\n",
      " [0.49401444 0.72536599 0.33716391 0.57913459]]\n",
      "Epoch 28/100, Loss: 0.12579069068928983, MSE: 0.25158138137857966\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.705107   -0.35362347]\n",
      " [ 0.34282544  0.05484074]\n",
      " [-0.65219409  0.99486201]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.22686326  0.56727392  0.29179658]]\n",
      "\n",
      "w:[[ 0.705107   -0.35362347]\n",
      " [ 0.34282544  0.05484074]\n",
      " [-0.65219409  0.99486201]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.22686326  0.56727392  0.29179658]]\n",
      "a:[[0.50252014 0.41494915 0.67154643 0.58941903]\n",
      " [0.49237841 0.5060877  0.57745552 0.59077677]\n",
      " [0.49388986 0.72520325 0.33701256 0.57889189]]\n",
      "Epoch 29/100, Loss: 0.12572658633029118, MSE: 0.25145317266058237\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70524331 -0.35349744]\n",
      " [ 0.34264645  0.0545729 ]\n",
      " [-0.65236631  0.99455182]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.22869352  0.56543977  0.28964555]]\n",
      "\n",
      "w:[[ 0.70524331 -0.35349744]\n",
      " [ 0.34264645  0.0545729 ]\n",
      " [-0.65236631  0.99455182]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.22869352  0.56543977  0.28964555]]\n",
      "a:[[0.50258727 0.41504493 0.67163571 0.58954749]\n",
      " [0.4922625  0.50590483 0.57729868 0.59055661]\n",
      " [0.49376906 0.7250451  0.33686611 0.57865646]]\n",
      "Epoch 30/100, Loss: 0.125668319842694, MSE: 0.251336639685388\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70537655 -0.35337524]\n",
      " [ 0.34247882  0.05431751]\n",
      " [-0.65253222  0.99424938]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.23043535  0.56369512  0.28758462]]\n",
      "\n",
      "w:[[ 0.70537655 -0.35337524]\n",
      " [ 0.34247882  0.05431751]\n",
      " [-0.65253222  0.99424938]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.23043535  0.56369512  0.28758462]]\n",
      "a:[[0.50265268 0.41513813 0.6717228  0.58967261]\n",
      " [0.49215267 0.50573115 0.57715055 0.59034806]\n",
      " [0.49365183 0.72489129 0.3367243  0.57842791]]\n",
      "Epoch 31/100, Loss: 0.1256153644147877, MSE: 0.2512307288295754\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70550679 -0.35325677]\n",
      " [ 0.34232198  0.05407395]\n",
      " [-0.65269217  0.99395429]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.23209275  0.56203584  0.28560971]]\n",
      "\n",
      "w:[[ 0.70550679 -0.35325677]\n",
      " [ 0.34232198  0.05407395]\n",
      " [-0.65269217  0.99395429]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.23209275  0.56203584  0.28560971]]\n",
      "a:[[0.50271644 0.41522881 0.67180775 0.58979449]\n",
      " [0.49204862 0.50556621 0.57701066 0.59015054]\n",
      " [0.49353798 0.72474158 0.33658686 0.57820586]]\n",
      "Epoch 32/100, Loss: 0.12556723927937458, MSE: 0.25113447855874915\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70563411 -0.35314193]\n",
      " [ 0.34217537  0.05384164]\n",
      " [-0.6528465   0.99366616]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.23366956  0.560458    0.28371689]]\n",
      "\n",
      "w:[[ 0.70563411 -0.35314193]\n",
      " [ 0.34217537  0.05384164]\n",
      " [-0.6528465   0.99366616]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.23366956  0.560458    0.28371689]]\n",
      "a:[[0.50277856 0.41531704 0.67189061 0.5899132 ]\n",
      " [0.49195005 0.50540955 0.57687861 0.58996348]\n",
      " [0.49342731 0.72459575 0.33645355 0.57798996]]\n",
      "Epoch 33/100, Loss: 0.12552350596416706, MSE: 0.2510470119283341\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70575859 -0.35303062]\n",
      " [ 0.34203848  0.05362   ]\n",
      " [-0.65299552  0.99338464]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.23516947  0.55895781  0.28190238]]\n",
      "\n",
      "w:[[ 0.70575859 -0.35303062]\n",
      " [ 0.34203848  0.05362   ]\n",
      " [-0.65299552  0.99338464]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.23516947  0.55895781  0.28190238]]\n",
      "a:[[0.50283912 0.41540289 0.67197144 0.59002883]\n",
      " [0.49185667 0.50526075 0.576754   0.58978636]\n",
      " [0.49331967 0.72445361 0.33632415 0.57777988]]\n",
      "Epoch 34/100, Loss: 0.1254837647967474, MSE: 0.2509675295934948\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70588031 -0.35292275]\n",
      " [ 0.34191081  0.05340851]\n",
      " [-0.65313952  0.99310936]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.23659601  0.55753166  0.28016258]]\n",
      "\n",
      "w:[[ 0.70588031 -0.35292275]\n",
      " [ 0.34191081  0.05340851]\n",
      " [-0.65313952  0.99310936]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.23659601  0.55753166  0.28016258]]\n",
      "a:[[0.50289814 0.41548642 0.67205031 0.59014147]\n",
      " [0.49176822 0.50511943 0.57663645 0.58961868]\n",
      " [0.49321487 0.72431495 0.33619844 0.57757531]]\n",
      "Epoch 35/100, Loss: 0.12544765165663857, MSE: 0.25089530331327714\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70599936 -0.35281822]\n",
      " [ 0.34179188  0.05320666]\n",
      " [-0.65327879  0.99284003]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.23795254  0.5561761   0.27849405]]\n",
      "\n",
      "w:[[ 0.70599936 -0.35281822]\n",
      " [ 0.34179188  0.05320666]\n",
      " [-0.65327879  0.99284003]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.23795254  0.5561761   0.27849405]]\n",
      "a:[[0.50295567 0.41556771 0.67212727 0.59025121]\n",
      " [0.49168446 0.50498519 0.57652559 0.58945995]\n",
      " [0.49311279 0.72417959 0.33607622 0.57737596]]\n",
      "Epoch 36/100, Loss: 0.12541483496502773, MSE: 0.25082966993005545\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70611581 -0.35271691]\n",
      " [ 0.34168126  0.05301396]\n",
      " [-0.6534136   0.99257632]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.23924232  0.55488781  0.27689348]]\n",
      "\n",
      "w:[[ 0.70611581 -0.35271691]\n",
      " [ 0.34168126  0.05301396]\n",
      " [-0.6534136   0.99257632]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.23924232  0.55488781  0.27689348]]\n",
      "a:[[0.50301177 0.41564681 0.67220238 0.59035815]\n",
      " [0.49160514 0.50485769 0.5764211  0.58930974]\n",
      " [0.49301325 0.72404735 0.3359573  0.57718154]]\n",
      "Epoch 37/100, Loss: 0.12538501290128984, MSE: 0.2507700258025797\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70622976 -0.35261874]\n",
      " [ 0.34157853  0.05282996]\n",
      " [-0.65354418  0.99231795]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24046843  0.55366366  0.27535772]]\n",
      "\n",
      "w:[[ 0.70622976 -0.35261874]\n",
      " [ 0.34157853  0.05282996]\n",
      " [-0.65354418  0.99231795]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24046843  0.55366366  0.27535772]]\n",
      "a:[[0.50306648 0.41572382 0.6722757  0.59046237]\n",
      " [0.49153003 0.50473657 0.57632264 0.58916761]\n",
      " [0.49291614 0.72391808 0.3358415  0.57699179]]\n",
      "Epoch 38/100, Loss: 0.12535791083455913, MSE: 0.25071582166911827\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70634128 -0.35252359]\n",
      " [ 0.34148327  0.05265424]\n",
      " [-0.65367078  0.99206465]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24163384  0.55250061  0.27388375]]\n",
      "\n",
      "w:[[ 0.70634128 -0.35252359]\n",
      " [ 0.34148327  0.05265424]\n",
      " [-0.65367078  0.99206465]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24163384  0.55250061  0.27388375]]\n",
      "a:[[0.50311985 0.41579878 0.6723473  0.59056396]\n",
      " [0.49145893 0.50462152 0.57622991 0.58903314]\n",
      " [0.49282132 0.72379162 0.33572866 0.57680647]]\n",
      "Epoch 39/100, Loss: 0.12533327895809143, MSE: 0.25066655791618286\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70645046 -0.35243137]\n",
      " [ 0.34139511  0.05248636]\n",
      " [-0.65379361  0.99181616]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24274137  0.55139579  0.2724687 ]]\n",
      "\n",
      "w:[[ 0.70645046 -0.35243137]\n",
      " [ 0.34139511  0.05248636]\n",
      " [-0.65379361  0.99181616]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24274137  0.55139579  0.2724687 ]]\n",
      "a:[[0.50317192 0.41587178 0.67241724 0.59066302]\n",
      " [0.49139162 0.50451224 0.57614262 0.58890597]\n",
      " [0.49272868 0.72366783 0.33561861 0.57662534]]\n",
      "Epoch 40/100, Loss: 0.1253108901139653, MSE: 0.2506217802279306\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70655739 -0.35234197]\n",
      " [ 0.3413137   0.05232595]\n",
      " [-0.65391288  0.99157223]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24379373  0.55034646  0.27110981]]\n",
      "\n",
      "w:[[ 0.70655739 -0.35234197]\n",
      " [ 0.3413137   0.05232595]\n",
      " [-0.65391288  0.99157223]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24379373  0.55034646  0.27110981]]\n",
      "a:[[0.50322273 0.41594288 0.67248556 0.59075963]\n",
      " [0.49132792 0.50440843 0.57606049 0.58878572]\n",
      " [0.49263808 0.72354655 0.3355112  0.57644818]]\n",
      "Epoch 41/100, Loss: 0.12529053779571658, MSE: 0.25058107559143317\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70666215 -0.3522553 ]\n",
      " [ 0.34123868  0.05217264]\n",
      " [-0.65402879  0.99133265]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.2447935   0.54934999  0.26980445]]\n",
      "\n",
      "w:[[ 0.70666215 -0.3522553 ]\n",
      " [ 0.34123868  0.05217264]\n",
      " [-0.65402879  0.99133265]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.2447935   0.54934999  0.26980445]]\n",
      "a:[[0.50327234 0.41601214 0.67255234 0.59085389]\n",
      " [0.49126765 0.50430982 0.57598328 0.58867204]\n",
      " [0.49254944 0.72342767 0.3354063  0.57627478]]\n",
      "Epoch 42/100, Loss: 0.1252720343167294, MSE: 0.2505440686334588\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70676481 -0.35217125]\n",
      " [ 0.34116974  0.05202607]\n",
      " [-0.65414152  0.99109718]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24574316  0.54840388  0.26855013]]\n",
      "\n",
      "w:[[ 0.70676481 -0.35217125]\n",
      " [ 0.34116974  0.05202607]\n",
      " [-0.65414152  0.99109718]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24574316  0.54840388  0.26855013]]\n",
      "a:[[0.50332079 0.41607965 0.67261762 0.59094587]\n",
      " [0.49121063 0.50421614 0.57591072 0.58856461]\n",
      " [0.49246265 0.72331107 0.33530378 0.57610495]]\n",
      "Epoch 43/100, Loss: 0.12525520913257024, MSE: 0.2505104182651405\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70686545 -0.35208974]\n",
      " [ 0.34110657  0.05188591]\n",
      " [-0.65425125  0.99086564]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24664505  0.54750574  0.26734445]]\n",
      "\n",
      "w:[[ 0.70686545 -0.35208974]\n",
      " [ 0.34110657  0.05188591]\n",
      " [-0.65425125  0.99086564]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24664505  0.54750574  0.26734445]]\n",
      "a:[[0.50336812 0.41614545 0.67268147 0.59103566]\n",
      " [0.49115669 0.50412716 0.57584258 0.58846311]\n",
      " [0.4923776  0.72319662 0.33520349 0.57593851]]\n",
      "Epoch 44/100, Loss: 0.1252399073059169, MSE: 0.2504798146118338\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70696416 -0.35201066]\n",
      " [ 0.34104888  0.05175185]\n",
      " [-0.65435814  0.99063781]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24750143  0.54665331  0.26618512]]\n",
      "\n",
      "w:[[ 0.70696416 -0.35201066]\n",
      " [ 0.34104888  0.05175185]\n",
      " [-0.65435814  0.99063781]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24750143  0.54665331  0.26618512]]\n",
      "a:[[0.50341438 0.41620962 0.67274394 0.59112336]\n",
      " [0.49110569 0.50404263 0.57577864 0.58836725]\n",
      " [0.49229422 0.72308421 0.33510534 0.57577527]]\n",
      "Epoch 45/100, Loss: 0.12522598810325902, MSE: 0.25045197620651805\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70706101 -0.35193393]\n",
      " [ 0.34099639  0.05162358]\n",
      " [-0.65446234  0.99041352]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24831444  0.5458444   0.26506998]]\n",
      "\n",
      "w:[[ 0.70706101 -0.35193393]\n",
      " [ 0.34099639  0.05162358]\n",
      " [-0.65446234  0.99041352]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24831444  0.5458444   0.26506998]]\n",
      "a:[[0.5034596  0.41627222 0.67280509 0.59120903]\n",
      " [0.49105748 0.50396233 0.5757187  0.58827674]\n",
      " [0.49221241 0.72297375 0.33500919 0.57561508]]\n",
      "Epoch 46/100, Loss: 0.12521332371312233, MSE: 0.25042664742624465\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70715606 -0.35185947]\n",
      " [ 0.34094884  0.05150082]\n",
      " [-0.65456401  0.9901926 ]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24908612  0.54507695  0.26399694]]\n",
      "\n",
      "w:[[ 0.70715606 -0.35185947]\n",
      " [ 0.34094884  0.05150082]\n",
      " [-0.65456401  0.9901926 ]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24908612  0.54507695  0.26399694]]\n",
      "a:[[0.50350382 0.4163333  0.67286496 0.59129275]\n",
      " [0.4910119  0.50388606 0.57566254 0.58819132]\n",
      " [0.49213209 0.72286513 0.33491496 0.57545777]]\n",
      "Epoch 47/100, Loss: 0.12520179807615817, MSE: 0.25040359615231633\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7072494  -0.35178717]\n",
      " [ 0.34090599  0.0513833 ]\n",
      " [-0.65466327  0.98997488]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.24981845  0.54434899  0.26296403]]\n",
      "\n",
      "w:[[ 0.7072494  -0.35178717]\n",
      " [ 0.34090599  0.0513833 ]\n",
      " [-0.65466327  0.98997488]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.24981845  0.54434899  0.26296403]]\n",
      "a:[[0.5035471  0.41639294 0.6729236  0.59137461]\n",
      " [0.49096885 0.50381362 0.57560999 0.58811074]\n",
      " [0.49205319 0.72275826 0.33482254 0.5753032 ]]\n",
      "Epoch 48/100, Loss: 0.1251913058180467, MSE: 0.2503826116360934\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7073411  -0.35171696]\n",
      " [ 0.34086759  0.05127076]\n",
      " [-0.65476027  0.98976021]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25051327  0.54365864  0.26196937]]\n",
      "\n",
      "w:[[ 0.7073411  -0.35171696]\n",
      " [ 0.34086759  0.05127076]\n",
      " [-0.65476027  0.98976021]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25051327  0.54365864  0.26196937]]\n",
      "a:[[0.50358945 0.41645117 0.67298107 0.59145468]\n",
      " [0.49092818 0.5037448  0.57556085 0.58803476]\n",
      " [0.49197564 0.72265306 0.33473184 0.57515123]]\n",
      "Epoch 49/100, Loss: 0.12518175127675607, MSE: 0.25036350255351214\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70743121 -0.35164875]\n",
      " [ 0.34083342  0.05116297]\n",
      " [-0.65485512  0.98954843]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25117237  0.54300412  0.26101114]]\n",
      "\n",
      "w:[[ 0.70743121 -0.35164875]\n",
      " [ 0.34083342  0.05116297]\n",
      " [-0.65485512  0.98954843]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25117237  0.54300412  0.26101114]]\n",
      "a:[[0.50363093 0.41650807 0.67303742 0.59153302]\n",
      " [0.49088978 0.50367944 0.57551497 0.58796314]\n",
      " [0.49189936 0.72254943 0.33464277 0.57500173]]\n",
      "Epoch 50/100, Loss: 0.1251730476162887, MSE: 0.2503460952325774\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70751981 -0.35158247]\n",
      " [ 0.34080327  0.05105968]\n",
      " [-0.65494794  0.98933942]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25179743  0.5423837   0.26008765]]\n",
      "\n",
      "w:[[ 0.70751981 -0.35158247]\n",
      " [ 0.34080327  0.05105968]\n",
      " [-0.65494794  0.98933942]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25179743  0.5423837   0.26008765]]\n",
      "a:[[0.50367156 0.41656368 0.67309268 0.59160972]\n",
      " [0.49085353 0.50361737 0.57547217 0.58789568]\n",
      " [0.4918243  0.72244731 0.33455524 0.57485457]]\n",
      "Epoch 51/100, Loss: 0.12516511601961072, MSE: 0.25033023203922145\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70760697 -0.35151805]\n",
      " [ 0.34077695  0.05096068]\n",
      " [-0.65503884  0.98913304]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25239009  0.54179577  0.25919725]]\n",
      "\n",
      "w:[[ 0.70760697 -0.35151805]\n",
      " [ 0.34077695  0.05096068]\n",
      " [-0.65503884  0.98913304]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25239009  0.54179577  0.25919725]]\n",
      "a:[[0.50371139 0.41661806 0.67314691 0.59168483]\n",
      " [0.49081934 0.50355841 0.57543231 0.58783217]\n",
      " [0.49175039 0.72234662 0.33446917 0.57470964]]\n",
      "Epoch 52/100, Loss: 0.12515788495400637, MSE: 0.25031576990801274\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70769273 -0.35145539]\n",
      " [ 0.34075425  0.05086576]\n",
      " [-0.65512792  0.98892917]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25295187  0.54123878  0.25833839]]\n",
      "\n",
      "w:[[ 0.70769273 -0.35145539]\n",
      " [ 0.34075425  0.05086576]\n",
      " [-0.65512792  0.98892917]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25295187  0.54123878  0.25833839]]\n",
      "a:[[0.50375044 0.41667126 0.67320015 0.59175842]\n",
      " [0.49078709 0.50350243 0.57539524 0.5877724 ]\n",
      " [0.49167758 0.72224729 0.33438449 0.57456682]]\n",
      "Epoch 53/100, Loss: 0.12515128950261506, MSE: 0.2503025790052301\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70777716 -0.35139444]\n",
      " [ 0.340735    0.05077472]\n",
      " [-0.65521528  0.98872769]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25348424  0.54071124  0.25750959]]\n",
      "\n",
      "w:[[ 0.70777716 -0.35139444]\n",
      " [ 0.340735    0.05077472]\n",
      " [-0.65521528  0.98872769]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25348424  0.54071124  0.25750959]]\n",
      "a:[[0.50378875 0.41672332 0.67325244 0.59183056]\n",
      " [0.49075669 0.50344926 0.57536082 0.58771621]\n",
      " [0.49160581 0.72214926 0.33430114 0.57442601]]\n",
      "Epoch 54/100, Loss: 0.12514527075639964, MSE: 0.2502905415127993\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70786032 -0.35133513]\n",
      " [ 0.34071903  0.05068738]\n",
      " [-0.65530102  0.98852848]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25398861  0.54021177  0.25670943]]\n",
      "\n",
      "w:[[ 0.70786032 -0.35133513]\n",
      " [ 0.34071903  0.05068738]\n",
      " [-0.65530102  0.98852848]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25398861  0.54021177  0.25670943]]\n",
      "a:[[0.50382635 0.4167743  0.67330381 0.59190131]\n",
      " [0.49072805 0.50339878 0.57532892 0.5876634 ]\n",
      " [0.49153502 0.72205245 0.33421904 0.57428711]]\n",
      "Epoch 55/100, Loss: 0.12513977526125383, MSE: 0.25027955052250767\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70794226 -0.35127738]\n",
      " [ 0.34070617  0.05060355]\n",
      " [-0.65538522  0.98833145]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25446631  0.53973901  0.25593657]]\n",
      "\n",
      "w:[[ 0.70794226 -0.35127738]\n",
      " [ 0.34070617  0.05060355]\n",
      " [-0.65538522  0.98833145]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25446631  0.53973901  0.25593657]]\n",
      "a:[[0.50386327 0.41682423 0.67335432 0.59197073]\n",
      " [0.49070108 0.50335085 0.57529941 0.58761383]\n",
      " [0.49146518 0.72195681 0.33413812 0.57415003]]\n",
      "Epoch 56/100, Loss: 0.12513475451538872, MSE: 0.25026950903077744\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70802304 -0.35122114]\n",
      " [ 0.34069627  0.05052307]\n",
      " [-0.65546796  0.98813649]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25491862  0.53929169  0.25518972]]\n",
      "\n",
      "w:[[ 0.70802304 -0.35122114]\n",
      " [ 0.34069627  0.05052307]\n",
      " [-0.65546796  0.98813649]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25491862  0.53929169  0.25518972]]\n",
      "a:[[0.50389954 0.41687317 0.673404   0.59203886]\n",
      " [0.4906757  0.50330534 0.57527218 0.58756732]\n",
      " [0.49139623 0.72186229 0.33405834 0.57401468]]\n",
      "Epoch 57/100, Loss: 0.1251301645125396, MSE: 0.2502603290250792\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70810271 -0.35116633]\n",
      " [ 0.34068918  0.05044578]\n",
      " [-0.65554932  0.98794351]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25534674  0.53886859  0.25446766]]\n",
      "\n",
      "w:[[ 0.70810271 -0.35116633]\n",
      " [ 0.34068918  0.05044578]\n",
      " [-0.65554932  0.98794351]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25534674  0.53886859  0.25446766]]\n",
      "a:[[0.50393518 0.41692116 0.67345287 0.59210578]\n",
      " [0.49065183 0.50326214 0.57524711 0.58752372]\n",
      " [0.49132814 0.72176883 0.33397963 0.57388096]]\n",
      "Epoch 58/100, Loss: 0.12512596532690945, MSE: 0.2502519306538189\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70818131 -0.35111291]\n",
      " [ 0.34068475  0.05037152]\n",
      " [-0.65562938  0.98775242]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25575183  0.53846856  0.25376923]]\n",
      "\n",
      "w:[[ 0.70818131 -0.35111291]\n",
      " [ 0.34068475  0.05037152]\n",
      " [-0.65562938  0.98775242]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25575183  0.53846856  0.25376923]]\n",
      "a:[[0.50397023 0.41696822 0.67350099 0.59217152]\n",
      " [0.4906294  0.50322114 0.5752241  0.58748291]\n",
      " [0.49126085 0.72167638 0.33390194 0.57374881]]\n",
      "Epoch 59/100, Loss: 0.12512212073611054, MSE: 0.2502442414722211\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7082589  -0.35106082]\n",
      " [ 0.34068287  0.05030015]\n",
      " [-0.65570821  0.98756313]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25613499  0.5380905   0.25309332]]\n",
      "\n",
      "w:[[ 0.7082589  -0.35106082]\n",
      " [ 0.34068287  0.05030015]\n",
      " [-0.65570821  0.98756313]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25613499  0.5380905   0.25309332]]\n",
      "a:[[0.5040047  0.41701442 0.67354838 0.59223615]\n",
      " [0.49060834 0.50318223 0.57520305 0.58744473]\n",
      " [0.49119433 0.72158489 0.33382522 0.57361815]]\n",
      "Epoch 60/100, Loss: 0.12511859787868765, MSE: 0.2502371957573753\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70833551 -0.35100999]\n",
      " [ 0.3406834   0.05023154]\n",
      " [-0.65578587  0.98737556]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25649726  0.53773335  0.25243887]]\n",
      "\n",
      "w:[[ 0.70833551 -0.35100999]\n",
      " [ 0.3406834   0.05023154]\n",
      " [-0.65578587  0.98737556]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25649726  0.53773335  0.25243887]]\n",
      "a:[[0.50403864 0.41705978 0.67359507 0.5922997 ]\n",
      " [0.49058857 0.5031453  0.57518385 0.58740906]\n",
      " [0.49112855 0.72149432 0.33374942 0.5734889 ]]\n",
      "Epoch 61/100, Loss: 0.12511536694310083, MSE: 0.25023073388620165\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7084112  -0.35096038]\n",
      " [ 0.34068622  0.05016554]\n",
      " [-0.65586243  0.98718964]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25683966  0.53739611  0.25180488]]\n",
      "\n",
      "w:[[ 0.7084112  -0.35096038]\n",
      " [ 0.34068622  0.05016554]\n",
      " [-0.65586243  0.98718964]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25683966  0.53739611  0.25180488]]\n",
      "a:[[0.50407205 0.41710433 0.67364109 0.59236223]\n",
      " [0.49057004 0.50311027 0.57516642 0.58737577]\n",
      " [0.49106347 0.72140462 0.33367449 0.57336099]]\n",
      "Epoch 62/100, Loss: 0.1251124008853189, MSE: 0.2502248017706378\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70848601 -0.35091193]\n",
      " [ 0.34069122  0.05010203]\n",
      " [-0.65593794  0.9870053 ]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25716313  0.53707784  0.25119039]]\n",
      "\n",
      "w:[[ 0.70848601 -0.35091193]\n",
      " [ 0.34069122  0.05010203]\n",
      " [-0.65593794  0.9870053 ]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25716313  0.53707784  0.25119039]]\n",
      "a:[[0.50410496 0.41714812 0.67368648 0.59242378]\n",
      " [0.49055269 0.50307703 0.57515068 0.58734476]\n",
      " [0.49099905 0.72131576 0.3336004  0.57323437]]\n",
      "Epoch 63/100, Loss: 0.1251096751724244, MSE: 0.2502193503448488\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70855997 -0.35086461]\n",
      " [ 0.34069829  0.0500409 ]\n",
      " [-0.65601247  0.98682246]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25746857  0.53677762  0.25059448]]\n",
      "\n",
      "w:[[ 0.70855997 -0.35086461]\n",
      " [ 0.34069829  0.0500409 ]\n",
      " [-0.65601247  0.98682246]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25746857  0.53677762  0.25059448]]\n",
      "a:[[0.50413739 0.41719117 0.67373126 0.5924844 ]\n",
      " [0.49053645 0.50304551 0.57513653 0.58731591]\n",
      " [0.49093527 0.7212277  0.3335271  0.57310897]]\n",
      "Epoch 64/100, Loss: 0.12510716754986145, MSE: 0.2502143350997229\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70863312 -0.35081835]\n",
      " [ 0.34070732  0.04998204]\n",
      " [-0.65608606  0.98664107]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25775686  0.5364946   0.25001629]]\n",
      "\n",
      "w:[[ 0.70863312 -0.35081835]\n",
      " [ 0.34070732  0.04998204]\n",
      " [-0.65608606  0.98664107]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25775686  0.5364946   0.25001629]]\n",
      "a:[[0.50416937 0.41723353 0.67377546 0.59254411]\n",
      " [0.49052128 0.50301561 0.5751239  0.58728912]\n",
      " [0.49087209 0.72114039 0.33345455 0.57298474]]\n",
      "Epoch 65/100, Loss: 0.1251048578301676, MSE: 0.2502097156603352\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70870551 -0.35077312]\n",
      " [ 0.34071823  0.04992533]\n",
      " [-0.65615877  0.98646105]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25802881  0.53622794  0.24945499]]\n",
      "\n",
      "w:[[ 0.70870551 -0.35077312]\n",
      " [ 0.34071823  0.04992533]\n",
      " [-0.65615877  0.98646105]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25802881  0.53622794  0.24945499]]\n",
      "a:[[0.50420092 0.41727521 0.67381911 0.59260298]\n",
      " [0.49050711 0.50298727 0.57511271 0.58726428]\n",
      " [0.49080949 0.72105381 0.33338272 0.57286161]]\n",
      "Epoch 66/100, Loss: 0.1251027277012245, MSE: 0.250205455402449\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70877716 -0.35072887]\n",
      " [ 0.34073091  0.04987068]\n",
      " [-0.65623064  0.98628236]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25828521  0.53597686  0.24890979]]\n",
      "\n",
      "w:[[ 0.70877716 -0.35072887]\n",
      " [ 0.34073091  0.04987068]\n",
      " [-0.65623064  0.98628236]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25828521  0.53597686  0.24890979]]\n",
      "a:[[0.50423205 0.41731625 0.67386222 0.59266102]\n",
      " [0.49049391 0.5029604  0.5751029  0.5872413 ]\n",
      " [0.49074744 0.72096792 0.33331158 0.57273954]]\n",
      "Epoch 67/100, Loss: 0.12510076055223848, MSE: 0.25020152110447696\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70884812 -0.35068556]\n",
      " [ 0.34074528  0.04981798]\n",
      " [-0.65630172  0.98610493]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25852681  0.53574063  0.24837994]]\n",
      "\n",
      "w:[[ 0.70884812 -0.35068556]\n",
      " [ 0.34074528  0.04981798]\n",
      " [-0.65630172  0.98610493]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25852681  0.53574063  0.24837994]]\n",
      "a:[[0.50426278 0.41735667 0.67390483 0.59271828]\n",
      " [0.49048162 0.50293493 0.5750944  0.58722009]\n",
      " [0.49068592 0.72088269 0.33324108 0.57261848]]\n",
      "Epoch 68/100, Loss: 0.12509894131582258, MSE: 0.25019788263164516\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7089184  -0.35064316]\n",
      " [ 0.34076126  0.04976716]\n",
      " [-0.65637205  0.98592871]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25875431  0.53551852  0.24786473]]\n",
      "\n",
      "w:[[ 0.7089184  -0.35064316]\n",
      " [ 0.34076126  0.04976716]\n",
      " [-0.65637205  0.98592871]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25875431  0.53551852  0.24786473]]\n",
      "a:[[0.50429313 0.41739651 0.67394696 0.5927748 ]\n",
      " [0.4904702  0.50291081 0.57508714 0.58720057]\n",
      " [0.49062489 0.7207981  0.3331712  0.57249838]]\n",
      "Epoch 69/100, Loss: 0.12509725632470006, MSE: 0.2501945126494001\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70898806 -0.35060161]\n",
      " [ 0.34077876  0.04971811]\n",
      " [-0.65644168  0.98575366]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25896841  0.53530987  0.24736347]]\n",
      "\n",
      "w:[[ 0.70898806 -0.35060161]\n",
      " [ 0.34077876  0.04971811]\n",
      " [-0.65644168  0.98575366]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25896841  0.53530987  0.24736347]]\n",
      "a:[[0.50432312 0.41743579 0.67398863 0.5928306 ]\n",
      " [0.49045961 0.50288795 0.57508106 0.58718265]\n",
      " [0.49056434 0.7207141  0.3331019  0.57237919]]\n",
      "Epoch 70/100, Loss: 0.1250956931816829, MSE: 0.2501913863633658\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7090571  -0.3505609 ]\n",
      " [ 0.34079771  0.04967076]\n",
      " [-0.65651064  0.98557973]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25916974  0.53511402  0.24687551]]\n",
      "\n",
      "w:[[ 0.7090571  -0.3505609 ]\n",
      " [ 0.34079771  0.04967076]\n",
      " [-0.65651064  0.98557973]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25916974  0.53511402  0.24687551]]\n",
      "a:[[0.50435277 0.41747453 0.67402986 0.59288571]\n",
      " [0.49044981 0.50286631 0.57507611 0.58716626]\n",
      " [0.49050425 0.72063068 0.33303317 0.57226088]]\n",
      "Epoch 71/100, Loss: 0.1250942406417017, MSE: 0.2501884812834034\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70912557 -0.35052098]\n",
      " [ 0.34081804  0.04962503]\n",
      " [-0.65657896  0.98540686]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25935891  0.53493036  0.24640024]]\n",
      "\n",
      "w:[[ 0.70912557 -0.35052098]\n",
      " [ 0.34081804  0.04962503]\n",
      " [-0.65657896  0.98540686]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25935891  0.53493036  0.24640024]]\n",
      "a:[[0.50438208 0.41751275 0.67407066 0.59294018]\n",
      " [0.49044076 0.50284582 0.57507222 0.58715132]\n",
      " [0.49044459 0.72054781 0.33296497 0.57214341]]\n",
      "Epoch 72/100, Loss: 0.12509288850477437, MSE: 0.25018577700954875\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70919349 -0.35048181]\n",
      " [ 0.34083968  0.04958083]\n",
      " [-0.6566467   0.98523502]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25953652  0.53475832  0.24593708]]\n",
      "\n",
      "w:[[ 0.70919349 -0.35048181]\n",
      " [ 0.34083968  0.04958083]\n",
      " [-0.6566467   0.98523502]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25953652  0.53475832  0.24593708]]\n",
      "a:[[0.50441108 0.41755049 0.67411107 0.59299402]\n",
      " [0.49043242 0.50282643 0.57506935 0.58713776]\n",
      " [0.49038535 0.72046547 0.33289728 0.57202673]]\n",
      "Epoch 73/100, Loss: 0.12509162751890368, MSE: 0.25018325503780736\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70926089 -0.35044338]\n",
      " [ 0.34086256  0.04953811]\n",
      " [-0.65671386  0.98506417]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25970312  0.53459733  0.24548545]]\n",
      "\n",
      "w:[[ 0.70926089 -0.35044338]\n",
      " [ 0.34086256  0.04953811]\n",
      " [-0.65671386  0.98506417]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25970312  0.53459733  0.24548545]]\n",
      "a:[[0.50443978 0.41758776 0.67415109 0.59304727]\n",
      " [0.49042476 0.50280808 0.57506745 0.58712552]\n",
      " [0.4903265  0.72038363 0.33283008 0.57191081]]\n",
      "Epoch 74/100, Loss: 0.12509044929198546, MSE: 0.2501808985839709\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70932779 -0.35040565]\n",
      " [ 0.34088663  0.0494968 ]\n",
      " [-0.6567805   0.98489426]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.25985925  0.53444686  0.24504483]]\n",
      "\n",
      "w:[[ 0.70932779 -0.35040565]\n",
      " [ 0.34088663  0.0494968 ]\n",
      " [-0.6567805   0.98489426]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.25985925  0.53444686  0.24504483]]\n",
      "a:[[0.50446819 0.41762457 0.67419075 0.59309995]\n",
      " [0.49041774 0.50279074 0.57506647 0.58711453]\n",
      " [0.49026804 0.72030228 0.33276334 0.57179562]]\n",
      "Epoch 75/100, Loss: 0.12508934621189402, MSE: 0.25017869242378804\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70939422 -0.35036858]\n",
      " [ 0.34091181  0.04945682]\n",
      " [-0.65684663  0.98472527]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26000541  0.5343064   0.24461471]]\n",
      "\n",
      "w:[[ 0.70939422 -0.35036858]\n",
      " [ 0.34091181  0.04945682]\n",
      " [-0.65684663  0.98472527]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26000541  0.5343064   0.24461471]]\n",
      "a:[[0.50449632 0.41766096 0.67423007 0.59315209]\n",
      " [0.49041134 0.50277434 0.57506637 0.58710474]\n",
      " [0.49020994 0.72022138 0.33269704 0.57168112]]\n",
      "Epoch 76/100, Loss: 0.12508831137398727, MSE: 0.25017662274797453\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70946019 -0.35033215]\n",
      " [ 0.34093807  0.04941812]\n",
      " [-0.65691229  0.98455716]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26014208  0.53417549  0.2441946 ]]\n",
      "\n",
      "w:[[ 0.70946019 -0.35033215]\n",
      " [ 0.34093807  0.04941812]\n",
      " [-0.65691229  0.98455716]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26014208  0.53417549  0.2441946 ]]\n",
      "a:[[0.5045242  0.41769694 0.67426905 0.59320371]\n",
      " [0.49040552 0.50275884 0.57506709 0.58709608]\n",
      " [0.49015218 0.72014093 0.33263115 0.57156728]]\n",
      "Epoch 77/100, Loss: 0.12508733851534484, MSE: 0.2501746770306897\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70952573 -0.35029634]\n",
      " [ 0.34096534  0.04938063]\n",
      " [-0.65697751  0.98438988]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26026972  0.53405365  0.24378405]]\n",
      "\n",
      "w:[[ 0.70952573 -0.35029634]\n",
      " [ 0.34096534  0.04938063]\n",
      " [-0.65697751  0.98438988]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26026972  0.53405365  0.24378405]]\n",
      "a:[[0.50455182 0.41773253 0.67430771 0.59325483]\n",
      " [0.49040026 0.50274421 0.57506861 0.5870885 ]\n",
      " [0.49009476 0.72006091 0.33256567 0.57145408]]\n",
      "Epoch 78/100, Loss: 0.12508642195511466, MSE: 0.2501728439102293\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70959087 -0.35026112]\n",
      " [ 0.34099357  0.04934431]\n",
      " [-0.65704229  0.98422342]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26038878  0.53394046  0.24338262]]\n",
      "\n",
      "w:[[ 0.70959087 -0.35026112]\n",
      " [ 0.34099357  0.04934431]\n",
      " [-0.65704229  0.98422342]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26038878  0.53394046  0.24338262]]\n",
      "a:[[0.50457921 0.41776775 0.67434608 0.59330548]\n",
      " [0.49039552 0.50273039 0.57507088 0.58708194]\n",
      " [0.49003766 0.71998128 0.33250057 0.57134149]]\n",
      "Epoch 79/100, Loss: 0.12508555654040165, MSE: 0.2501711130808033\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70965561 -0.35022647]\n",
      " [ 0.34102271  0.0493091 ]\n",
      " [-0.65710669  0.98405775]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26049966  0.53383549  0.24298988]]\n",
      "\n",
      "w:[[ 0.70965561 -0.35022647]\n",
      " [ 0.34102271  0.0493091 ]\n",
      " [-0.65710669  0.98405775]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26049966  0.53383549  0.24298988]]\n",
      "a:[[0.50460637 0.4178026  0.67438415 0.59335568]\n",
      " [0.49039129 0.50271736 0.57507387 0.58707637]\n",
      " [0.48998086 0.71990205 0.33243584 0.57122947]]\n",
      "Epoch 80/100, Loss: 0.1250847375971847, MSE: 0.2501694751943694\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70971999 -0.35019235]\n",
      " [ 0.34105273  0.04927495]\n",
      " [-0.6571707   0.98389282]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26060277  0.53373836  0.24260544]]\n",
      "\n",
      "w:[[ 0.70971999 -0.35019235]\n",
      " [ 0.34105273  0.04927495]\n",
      " [-0.6571707   0.98389282]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26060277  0.53373836  0.24260544]]\n",
      "a:[[0.50463331 0.41783712 0.67442195 0.59340545]\n",
      " [0.49038754 0.50270507 0.57507753 0.58707173]\n",
      " [0.48992435 0.71982319 0.33237145 0.57111801]]\n",
      "Epoch 81/100, Loss: 0.12508396088579476, MSE: 0.25016792177158953\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70978401 -0.35015876]\n",
      " [ 0.34108357  0.04924181]\n",
      " [-0.65723437  0.98372863]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26069849  0.53364869  0.24222893]]\n",
      "\n",
      "w:[[ 0.70978401 -0.35015876]\n",
      " [ 0.34108357  0.04924181]\n",
      " [-0.65723437  0.98372863]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26069849  0.53364869  0.24222893]]\n",
      "a:[[0.50466004 0.4178713  0.67445949 0.5934548 ]\n",
      " [0.49038425 0.50269349 0.57508185 0.58706797]\n",
      " [0.48986812 0.71974469 0.3323074  0.57100708]]\n",
      "Epoch 82/100, Loss: 0.12508322256053153, MSE: 0.25016644512106306\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7098477  -0.35012566]\n",
      " [ 0.34111519  0.04920963]\n",
      " [-0.65729769  0.98356513]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26078716  0.53356611  0.24185997]]\n",
      "\n",
      "w:[[ 0.7098477  -0.35012566]\n",
      " [ 0.34111519  0.04920963]\n",
      " [-0.65729769  0.98356513]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26078716  0.53356611  0.24185997]]\n",
      "a:[[0.50468658 0.41790517 0.67449678 0.59350377]\n",
      " [0.49038139 0.50268258 0.57508678 0.58706507]\n",
      " [0.48981216 0.71966654 0.33224367 0.57089666]]\n",
      "Epoch 83/100, Loss: 0.12508251913303314, MSE: 0.2501650382660663\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70991108 -0.35009305]\n",
      " [ 0.34114756  0.04917838]\n",
      " [-0.65736071  0.98340231]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26086915  0.53349029  0.24149823]]\n",
      "\n",
      "w:[[ 0.70991108 -0.35009305]\n",
      " [ 0.34114756  0.04917838]\n",
      " [-0.65736071  0.98340231]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26086915  0.53349029  0.24149823]]\n",
      "a:[[0.50471292 0.41793875 0.67453383 0.59355235]\n",
      " [0.49037894 0.50267232 0.5750923  0.58706296]\n",
      " [0.48975645 0.71958871 0.33218023 0.57078672]]\n",
      "Epoch 84/100, Loss: 0.12508184743905168, MSE: 0.25016369487810336\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.70997415 -0.35006089]\n",
      " [ 0.34118063  0.04914801]\n",
      " [-0.65742343  0.98324015]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26094476  0.5334209   0.24114339]]\n",
      "\n",
      "w:[[ 0.70997415 -0.35006089]\n",
      " [ 0.34118063  0.04914801]\n",
      " [-0.65742343  0.98324015]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26094476  0.5334209   0.24114339]]\n",
      "a:[[0.50473909 0.41797204 0.67457066 0.59360058]\n",
      " [0.49037688 0.50266267 0.57509837 0.58706162]\n",
      " [0.489701   0.7195112  0.33211709 0.57067726]]\n",
      "Epoch 85/100, Loss: 0.12508120460831706, MSE: 0.25016240921663413\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71003693 -0.35002917]\n",
      " [ 0.34121438  0.04911848]\n",
      " [-0.65748588  0.98307861]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26101433  0.53335763  0.24079512]]\n",
      "\n",
      "w:[[ 0.71003693 -0.35002917]\n",
      " [ 0.34121438  0.04911848]\n",
      " [-0.65748588  0.98307861]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26101433  0.53335763  0.24079512]]\n",
      "a:[[0.50476508 0.41800505 0.67460727 0.59364846]\n",
      " [0.4903752  0.50265361 0.57510497 0.58706101]\n",
      " [0.48964577 0.719434   0.33205423 0.57056823]]\n",
      "Epoch 86/100, Loss: 0.12508058803720296, MSE: 0.2501611760744059\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71009944 -0.34999788]\n",
      " [ 0.34124876  0.04908975]\n",
      " [-0.65754806  0.98291769]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26107813  0.53330019  0.24045313]]\n",
      "\n",
      "w:[[ 0.71009944 -0.34999788]\n",
      " [ 0.34124876  0.04908975]\n",
      " [-0.65754806  0.98291769]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26107813  0.53330019  0.24045313]]\n",
      "a:[[0.50479091 0.4180378  0.67464367 0.59369601]\n",
      " [0.49037388 0.5026451  0.57511208 0.5870611 ]\n",
      " [0.48959078 0.71935709 0.33199163 0.57045964]]\n",
      "Epoch 87/100, Loss: 0.1250799953639341, MSE: 0.2501599907278682\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7101617  -0.349967  ]\n",
      " [ 0.34128375  0.04906179]\n",
      " [-0.65761     0.98275736]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26113646  0.5332483   0.24011715]]\n",
      "\n",
      "w:[[ 0.7101617  -0.349967  ]\n",
      " [ 0.34128375  0.04906179]\n",
      " [-0.65761     0.98275736]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26113646  0.5332483   0.24011715]]\n",
      "a:[[0.50481659 0.4180703  0.67467988 0.59374325]\n",
      " [0.49037289 0.50263712 0.57511966 0.58706185]\n",
      " [0.489536   0.71928046 0.33192928 0.57035146]]\n",
      "Epoch 88/100, Loss: 0.1250794244460987, MSE: 0.2501588488921974\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7102237  -0.34993651]\n",
      " [ 0.34131931  0.04903457]\n",
      " [-0.65767171  0.9825976 ]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26118958  0.53320169  0.23978689]]\n",
      "\n",
      "w:[[ 0.7102237  -0.34993651]\n",
      " [ 0.34131931  0.04903457]\n",
      " [-0.65767171  0.9825976 ]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26118958  0.53320169  0.23978689]]\n",
      "a:[[0.50484211 0.41810256 0.6747159  0.59379019]\n",
      " [0.49037222 0.50262965 0.5751277  0.58706322]\n",
      " [0.48948143 0.7192041  0.33186717 0.57024368]]\n",
      "Epoch 89/100, Loss: 0.1250788733402521, MSE: 0.2501577466805042\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71028548 -0.34990639]\n",
      " [ 0.34135542  0.04900805]\n",
      " [-0.6577332   0.98243839]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26123775  0.5331601   0.23946211]]\n",
      "\n",
      "w:[[ 0.71028548 -0.34990639]\n",
      " [ 0.34135542  0.04900805]\n",
      " [-0.6577332   0.98243839]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26123775  0.5331601   0.23946211]]\n",
      "a:[[0.5048675  0.41813459 0.67475174 0.59383685]\n",
      " [0.49037187 0.50262266 0.57513617 0.5870652 ]\n",
      " [0.48942707 0.71912801 0.3318053  0.57013627]]\n",
      "Epoch 90/100, Loss: 0.1250783402834166, MSE: 0.2501566805668332\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71034703 -0.34987663]\n",
      " [ 0.34139204  0.0489822 ]\n",
      " [-0.65779449  0.98227972]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26128122  0.53312329  0.23914256]]\n",
      "\n",
      "w:[[ 0.71034703 -0.34987663]\n",
      " [ 0.34139204  0.0489822 ]\n",
      " [-0.65779449  0.98227972]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26128122  0.53312329  0.23914256]]\n",
      "a:[[0.50489274 0.4181664  0.67478741 0.59388323]\n",
      " [0.4903718  0.50261614 0.57514506 0.58706775]\n",
      " [0.48937289 0.71905216 0.33174365 0.57002922]]\n",
      "Epoch 91/100, Loss: 0.12507782367630185, MSE: 0.2501556473526037\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71040837 -0.34984722]\n",
      " [ 0.34142916  0.048957  ]\n",
      " [-0.65785559  0.98212156]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26132021  0.53309103  0.23882801]]\n",
      "\n",
      "w:[[ 0.71040837 -0.34984722]\n",
      " [ 0.34142916  0.048957  ]\n",
      " [-0.65785559  0.98212156]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26132021  0.53309103  0.23882801]]\n",
      "a:[[0.50491786 0.41819801 0.67482292 0.59392935]\n",
      " [0.49037201 0.50261005 0.57515433 0.58707084]\n",
      " [0.4893189  0.71897656 0.33168221 0.56992253]]\n",
      "Epoch 92/100, Loss: 0.12507732206808544, MSE: 0.2501546441361709\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71046951 -0.34981815]\n",
      " [ 0.34146673  0.04893241]\n",
      " [-0.65791652  0.98196391]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26135495  0.5330631   0.23851823]]\n",
      "\n",
      "w:[[ 0.71046951 -0.34981815]\n",
      " [ 0.34146673  0.04893241]\n",
      " [-0.65791652  0.98196391]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26135495  0.5330631   0.23851823]]\n",
      "a:[[0.50494285 0.41822941 0.67485828 0.59397522]\n",
      " [0.49037249 0.50260438 0.57516398 0.58707445]\n",
      " [0.48926509 0.71890119 0.33162097 0.56981617]]\n",
      "Epoch 93/100, Loss: 0.1250768341426088, MSE: 0.2501536682852176\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71053047 -0.3497894 ]\n",
      " [ 0.34150475  0.04890841]\n",
      " [-0.65797728  0.98180675]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26138565  0.53303929  0.23821302]]\n",
      "\n",
      "w:[[ 0.71053047 -0.3497894 ]\n",
      " [ 0.34150475  0.04890841]\n",
      " [-0.65797728  0.98180675]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26138565  0.53303929  0.23821302]]\n",
      "a:[[0.50496772 0.41826061 0.67489349 0.59402085]\n",
      " [0.49037322 0.5025991  0.57517398 0.58707855]\n",
      " [0.48921146 0.71882605 0.33155993 0.56971013]]\n",
      "Epoch 94/100, Loss: 0.1250763587058565, MSE: 0.250152717411713\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71059125 -0.34976095]\n",
      " [ 0.34154319  0.04888497]\n",
      " [-0.65803789  0.98165007]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.2614125   0.53301941  0.23791217]]\n",
      "\n",
      "w:[[ 0.71059125 -0.34976095]\n",
      " [ 0.34154319  0.04888497]\n",
      " [-0.65803789  0.98165007]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.2614125   0.53301941  0.23791217]]\n",
      "a:[[0.50499249 0.41829164 0.67492856 0.59406626]\n",
      " [0.49037418 0.50259421 0.57518432 0.58708313]\n",
      " [0.48915799 0.71875113 0.33149908 0.56960441]]\n",
      "Epoch 95/100, Loss: 0.12507589467459992, MSE: 0.25015178934919985\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71065185 -0.34973281]\n",
      " [ 0.34158202  0.04886207]\n",
      " [-0.65809835  0.98149385]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26143571  0.53300325  0.2376155 ]]\n",
      "\n",
      "w:[[ 0.71065185 -0.34973281]\n",
      " [ 0.34158202  0.04886207]\n",
      " [-0.65809835  0.98149385]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26143571  0.53300325  0.2376155 ]]\n",
      "a:[[0.50501714 0.41832248 0.67496349 0.59411144]\n",
      " [0.49037538 0.50258968 0.57519497 0.58708815]\n",
      " [0.48910468 0.71867642 0.33143841 0.56949898]]\n",
      "Epoch 96/100, Loss: 0.12507544106609725, MSE: 0.2501508821321945\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.7107123  -0.34970495]\n",
      " [ 0.34162123  0.04883968]\n",
      " [-0.65815868  0.98133807]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26145545  0.53299065  0.23732282]]\n",
      "\n",
      "w:[[ 0.7107123  -0.34970495]\n",
      " [ 0.34162123  0.04883968]\n",
      " [-0.65815868  0.98133807]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26145545  0.53299065  0.23732282]]\n",
      "a:[[0.50504169 0.41835316 0.6749983  0.59415642]\n",
      " [0.49037679 0.5025855  0.57520593 0.58709359]\n",
      " [0.48905152 0.71860191 0.3313779  0.56939384]]\n",
      "Epoch 97/100, Loss: 0.12507499698875063, MSE: 0.25014999397750126\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71077259 -0.34967737]\n",
      " [ 0.34166079  0.04881779]\n",
      " [-0.65821889  0.98118274]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.2614719   0.53298142  0.23703396]]\n",
      "\n",
      "w:[[ 0.71077259 -0.34967737]\n",
      " [ 0.34166079  0.04881779]\n",
      " [-0.65821889  0.98118274]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.2614719   0.53298142  0.23703396]]\n",
      "a:[[0.50506614 0.41838368 0.67503298 0.5942012 ]\n",
      " [0.49037841 0.50258164 0.57521718 0.58709945]\n",
      " [0.48899851 0.71852759 0.33131756 0.56928898]]\n",
      "Epoch 98/100, Loss: 0.1250745616336325, MSE: 0.250149123267265\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71083274 -0.34965005]\n",
      " [ 0.34170069  0.04879637]\n",
      " [-0.65827898  0.98102782]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26148521  0.53297541  0.23674875]]\n",
      "\n",
      "w:[[ 0.71083274 -0.34965005]\n",
      " [ 0.34170069  0.04879637]\n",
      " [-0.65827898  0.98102782]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26148521  0.53297541  0.23674875]]\n",
      "a:[[0.5050905  0.41841404 0.67506755 0.59424578]\n",
      " [0.49038022 0.5025781  0.5752287  0.58710569]\n",
      " [0.48894565 0.71845347 0.33125738 0.56918438]]\n",
      "Epoch 99/100, Loss: 0.12507413426680003, MSE: 0.25014826853360006\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71089276 -0.349623  ]\n",
      " [ 0.3417409   0.04877541]\n",
      " [-0.65833896  0.98087333]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26149556  0.53297246  0.23646704]]\n",
      "\n",
      "w:[[ 0.71089276 -0.349623  ]\n",
      " [ 0.3417409   0.04877541]\n",
      " [-0.65833896  0.98087333]]\n",
      "a:[[0 0 1 1]\n",
      " [0 1 0 1]]\n",
      "w:[[-0.26149556  0.53297246  0.23646704]]\n",
      "a:[[0.50511477 0.41844425 0.67510201 0.59429019]\n",
      " [0.49038222 0.50257486 0.57524049 0.58711229]\n",
      " [0.48889292 0.71837953 0.33119736 0.56908005]]\n",
      "Epoch 100/100, Loss: 0.1250737142223235, MSE: 0.250147428444647\n",
      "Weights:\n",
      "Layer 1:\n",
      "W1:\n",
      "[[ 0.71095264 -0.34959619]\n",
      " [ 0.34178142  0.04875488]\n",
      " [-0.65839885  0.98071923]]\n",
      "Layer 2:\n",
      "W2:\n",
      "[[-0.26150308  0.53297242  0.23618868]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "layers_dim = [2, 3, 1]  # Example: 2 input units, 3 units in the hidden layer, 1 output unit\n",
    "activation_func = SigmoidActivation  # Use Sigmoid activation function\n",
    "loss = L2Loss()  # Use L2 loss function\n",
    "model = Model(layers_dim, activation_func, loss)\n",
    "\n",
    "# Assuming X and y are your input and output data\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "num_epochs = 100  # Specify the number of epochs\n",
    "learning_rate = 0.1  # Specify the learning rate\n",
    "model.train(X.T, y.T, num_epochs, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
