{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf2zzP5LKmpR"
      },
      "source": [
        "#Gates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "A6cqznZGKdCy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Gate:\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class AddGate(Gate):\n",
        "    def forward(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        return x + y\n",
        "    def backward(self, dz):\n",
        "        dx = dz * np.ones_like(self.x)\n",
        "        dy = dz * np.ones_like(self.y)\n",
        "        return dy\n",
        "\n",
        "class MultiplyGate:\n",
        "    def forward(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        return np.dot(x, y)\n",
        "\n",
        "    def backward(self, dz):\n",
        "        dz=dz.reshape(self.x.shape[0],1)\n",
        "        self.y=self.y.reshape(self.y.shape[0],1)\n",
        "\n",
        "        dx = np.dot(dz, self.y.T)\n",
        "        dy = np.dot(self.x.T, dz)\n",
        "        return dx, dy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bftLDqpK3i-"
      },
      "source": [
        "#Activation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "Lu1ZpAPrK5xf"
      },
      "outputs": [],
      "source": [
        "class SoftmaxActivation(Gate):\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "    def backward(self, dz):\n",
        "        softmax_x = self.forward(self.x)\n",
        "        dx = dz * softmax_x * (1 - softmax_x)\n",
        "        return dx\n",
        "\n",
        "class SigmoidActivation(Gate):\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        if x >= 0:\n",
        "          self.sig =  1. / ( 1. + np.exp(-x) )\n",
        "        else:\n",
        "          self.sig =  np.exp(x) / ( 1. + np.exp(x) )\n",
        "        print(f\"self.sig = {self.sig}\")\n",
        "        return self.sig\n",
        "\n",
        "    def backward(self, dz):\n",
        "        dx = dz * self.sig * (1 - self.sig)\n",
        "        return dx\n",
        "\n",
        "class ReLUActivation(Gate):\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def backward(self, dz):\n",
        "        print(f\"ReLU.x = {self.x}\")\n",
        "        dx = dz * np.where(self.x > 0, 1, 0)\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhUsJ5myLKah"
      },
      "source": [
        "#Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "YzxLvFG0LMkk"
      },
      "outputs": [],
      "source": [
        "class BinaryCrossEntropyLoss(Gate):\n",
        "    def forward(self, y_pred, y_true):\n",
        "        self.y_pred = y_pred.flatten()\n",
        "        epsilon = 1e-7\n",
        "        self.y_pred = np.clip(self.y_pred, epsilon, 1 - epsilon)\n",
        "        self.y_true = y_true\n",
        "        return -np.mean(self.y_true * np.log(self.y_pred) + (1 - self.y_true) * np.log(1 - self.y_pred))\n",
        "\n",
        "    def backward(self):\n",
        "        #dy_pred = - (self.y_true / self.y_pred) + ((1 - self.y_true) / (1 - self.y_pred))\n",
        "        dy_pred = (self.y_pred - self.y_true) / (self.y_pred * (1 - self.y_pred))\n",
        "        return dy_pred\n",
        "\n",
        "class L2Loss(Gate):\n",
        "    def forward(self, y_pred, y_true):\n",
        "        self.y_pred = y_pred\n",
        "        self.y_true = y_true\n",
        "        return 0.5 * np.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "    def backward(self,y_pred, y_true):\n",
        "        dx = y_pred - y_true\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCidlPClgIJ"
      },
      "source": [
        "#My Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "mAzVaONAks3E"
      },
      "outputs": [],
      "source": [
        "class my_Model:\n",
        "  def __init__(self,layers_dim, actiation_func, loss):\n",
        "    self.layers=[]\n",
        "    self.layers_dim = layers_dim\n",
        "    self.num_layers=len(layers_dim)\n",
        "    self.grads=[]\n",
        "    self.weightsgrads=[]\n",
        "    self.biasgrads=[]\n",
        "\n",
        "    if len(layers_dim)!=len(actiation_func)+1:\n",
        "      raise ValueError(\"the number of layers is not equal to the number of activation funcs\")\n",
        "    for i in range(0,self.num_layers - 1):\n",
        "      layer=[]\n",
        "      layer.append(MultiplyGate())\n",
        "      layer.append(AddGate())\n",
        "\n",
        "      if actiation_func[i] =='sigmoid':\n",
        "        layer.append(SigmoidActivation())\n",
        "      if actiation_func[i] =='relu':\n",
        "        layer.append(ReLUActivation())\n",
        "      if actiation_func[i] =='softmax':\n",
        "        layer.append(SoftmaxActivation())\n",
        "\n",
        "      self.layers.append(layer)\n",
        "\n",
        "    if loss=='CE':\n",
        "      self.loss=BinaryCrossEntropyLoss()\n",
        "    elif loss=='L2':\n",
        "      self.loss=L2Loss()\n",
        "    self.parameters=self.initialise_parameters()\n",
        "\n",
        "  def initialise_parameters(self):\n",
        "    parameters = []\n",
        "    for i in range(1, self.num_layers):\n",
        "      weights = np.random.randn(self.layers_dim[i], self.layers_dim[i-1])\n",
        "      biases = np.random.randn(self.layers_dim[i])\n",
        "      layer_param = {'weights': weights, 'biases': biases}\n",
        "      parameters.append(layer_param)\n",
        "    return parameters\n",
        "\n",
        "  def forward(self, x):\n",
        "    for i in range(0,self.num_layers-1):\n",
        "      x = self.layers[i][0].forward(self.parameters[i]['weights'], x)\n",
        "      #print(f\"Layer {i+1},After multip: {x}\")\n",
        "      x = x.flatten()\n",
        "      x = self.layers[i][1].forward(x, self.parameters[i]['biases'])\n",
        "      #print(f\"Layer {i+1},After addition: {x}\")\n",
        "      x = self.layers[i][2].forward(x)\n",
        "      #print(f\"Layer {i+1},After activation: {x}\")\n",
        "    return(x)\n",
        "\n",
        "  def predict(self, X):\n",
        "    y_pred = []\n",
        "    X = np.array(X)\n",
        "    if not isinstance(X[0], np.ndarray):\n",
        "      y = self.forward(X)\n",
        "      y_pred.append(y)\n",
        "\n",
        "    else:\n",
        "      for i in range(len(X)):\n",
        "        y = self.forward(X[i])\n",
        "        y_pred.append(y)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return (y_pred)\n",
        "\n",
        "  def backward(self, computed_loss):\n",
        "    self.grads.append(computed_loss)\n",
        "    dz = computed_loss #upstream gradient of last activation function\n",
        "    for i in range(self.num_layers - 2, -1, -1):\n",
        "      print(f\"layer {i + 1}\")\n",
        "      dz = self.layers[i][2].backward(dz)\n",
        "      print(f\"upstream grad of layer activation function = {dz}\")\n",
        "      db = self.layers[i][1].backward(dz)\n",
        "      print(f\"bias grad = {db}\")\n",
        "      dw, dz = self.layers[i][0].backward(dz)\n",
        "      print(f\"weights grad = {dw}\")\n",
        "      print(f\"upstream grad of next layer = {dz}\")\n",
        "\n",
        "      self.weightsgrads.append(dw)\n",
        "      self.biasgrads.append(db)\n",
        "      self.grads.append(dz)\n",
        "\n",
        "\n",
        "  def train(self, X_train, Y_train, learning_rate, num_epochs, gradient_descent_method='batch',batch_size=None,patience=10):\n",
        "    ss=[]\n",
        "    for i in range (0,num_epochs):\n",
        "\n",
        "      print(f\"\\nEpoch {i+1}:\")\n",
        "      if gradient_descent_method=='batch':\n",
        "        y_pred=self.predict(X_train)\n",
        "        loss=self.loss.forward(y_pred,Y_train)\n",
        "        print(f\"loss = {loss}\")\n",
        "        print(\"Starting back propagation\")\n",
        "        computed_loss=self.loss.backward()\n",
        "        computed_loss=np.array(computed_loss)\n",
        "        computed_loss=np.mean(computed_loss)\n",
        "        print(f\"upstream gradient of layer 2 func = {computed_loss}\")\n",
        "        self.backward(computed_loss)\n",
        "\n",
        "        self.update_parameters(learning_rate)\n",
        "        ss.append(loss)\n",
        "\n",
        "  def update_parameters(self,learning_rate):\n",
        "    parameters=[]\n",
        "    for i in range(0,len(self.parameters)):\n",
        "      #print(f\"old weights = {self.parameters[i]['weights'][0]}]\")\n",
        "      w=self.parameters[i]['weights']-learning_rate*self.weightsgrads[len(self.parameters)-i-1]\n",
        "      print(f\"new weights of layer {i+1} = {w[0]}\")\n",
        "\n",
        "      # print(\"output\",self.parameters[i]['weights'].shape)\n",
        "      s=np.array(self.biasgrads[len(self.parameters)-i-1])\n",
        "      b=self.parameters[i]['biases']-learning_rate*s\n",
        "      layer_param = {'weights': w, 'biases': b}\n",
        "      parameters.append(layer_param)\n",
        "    self.parameters=parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN3uDT1dlkh1"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "cKZTDcY3LXxb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "class Model:\n",
        "    def __init__(self,layers_dim, actiation_func, loss):\n",
        "        self.layers=[]\n",
        "        self.activFunc=[]\n",
        "        self.layers_dim = layers_dim\n",
        "        self.num_layers=len(layers_dim)\n",
        "        self.grads=[]\n",
        "        self.weightsgrads=[]\n",
        "        self.biasgrads=[]\n",
        "        self.stop_count=0\n",
        "\n",
        "        if len(layers_dim)!=len(actiation_func)+1:\n",
        "            raise ValueError(\"the number of layers is not equal to the number of activation funcs\")\n",
        "        for i in range(0,len(layers_dim)-1):\n",
        "            layer=[]\n",
        "            layer.append(MultiplyGate())\n",
        "            layer.append(AddGate())\n",
        "            self.layers.append(layer)\n",
        "        for i in range(0,len(actiation_func)):\n",
        "            if actiation_func[i] =='sigmoid':\n",
        "                self.activFunc.append(SigmoidActivation())\n",
        "            if actiation_func[i] =='relu':\n",
        "                self.activFunc.append(ReLUActivation())\n",
        "            if actiation_func[i] =='softmax':\n",
        "                self.activFunc.append(SoftmaxActivation())\n",
        "        if loss=='CE':\n",
        "            self.loss=BinaryCrossEntropyLoss()\n",
        "        elif loss=='L2':\n",
        "            self.loss=L2Loss()\n",
        "        self.parameters=self.initialise_parameters()\n",
        "\n",
        "    def initialise_parameters(self):\n",
        "        parameters = []\n",
        "        for i in range(1, len(self.layers_dim)):\n",
        "            weights = np.random.rand(self.layers_dim[i],self.layers_dim[i-1])\n",
        "            biases = np.random.rand(self.layers_dim[i])\n",
        "            layer_param = {'weights': weights, 'biases': biases}\n",
        "            parameters.append(layer_param)\n",
        "        return parameters\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(0,self.num_layers-1):\n",
        "            x = self.layers[i][0].forward(self.parameters[i]['weights'],x)\n",
        "            x = x.flatten()\n",
        "            x = self.layers[i][1].forward(x, self.parameters[i]['biases'])\n",
        "            x = self.activFunc[i].forward(x)\n",
        "\n",
        "        return(x)\n",
        "\n",
        "    def backward(self,losscomputed):\n",
        "        dy = losscomputed\n",
        "        self.grads.append(dy)\n",
        "        dz = dy #upstream gradient of last activation function\n",
        "        for i in range(self.num_layers-1, 0, -1):\n",
        "            print(f\"Flayer no {i+1}\")\n",
        "            dz = self.activFunc[i-1].backward(dz)\n",
        "            dz = dz.flatten()\n",
        "            if len(dz)==1:\n",
        "                dz=dz[0]\n",
        "            print(f\"dz = {dz}\")\n",
        "            db = self.layers[i-1][1].backward(dz)\n",
        "            dw,dz = self.layers[i-1][0].backward(dz)\n",
        "            self.weightsgrads.append(dw)\n",
        "            dz=dz.flatten()\n",
        "            self.biasgrads.append(db)\n",
        "            print(f\"weight gradients = {dw}\")\n",
        "            print(f\"bias gradients = {db}\")\n",
        "            self.grads.append(dz)\n",
        "\n",
        "    def train(self, X_train, Y_train, learning_rate, num_epochs, gradient_descent_method='batch',batch_size=None,patience=10):\n",
        "        ss=[]\n",
        "        learning_rate_sch = LearningRateScheduler('cosine', learning_rate, num_epochs)\n",
        "        for i in range (0,num_epochs):\n",
        "            self.dropout()\n",
        "            if gradient_descent_method=='batch':\n",
        "                y_pred=self.predict(X_train)\n",
        "                loss=self.loss.forward(y_pred,Y_train)\n",
        "                # print(loss)\n",
        "                computed_loss=self.loss.backward()\n",
        "                computed_loss=np.array(computed_loss)\n",
        "                computed_loss=np.mean(computed_loss)\n",
        "                # print(computed_loss)\n",
        "\n",
        "                self.backward(computed_loss)\n",
        "\n",
        "                self.update_parameters(learning_rate)\n",
        "                ss.append(loss)\n",
        "                # print(loss)\n",
        "                if self.check_early_stopping(ss):\n",
        "                    break\n",
        "\n",
        "            if gradient_descent_method=='stocastic_batch':\n",
        "                for j in range (0,len(X_train)):\n",
        "                    sample=[]\n",
        "                    sample.append(X_train[j])\n",
        "                    lr=0.1*self.learning_rate\n",
        "                    y_pred=self.predict(sample)\n",
        "                    loss=self.loss.forward(y_pred,Y_train[j])\n",
        "                    # print(loss)\n",
        "                    computed_loss=self.loss.backward()\n",
        "                    computed_loss=np.array(computed_loss)\n",
        "                    computed_loss=np.mean(computed_loss)\n",
        "                    # print(computed_loss)\n",
        "                    self.backward(computed_loss)\n",
        "                    self.update_parameters(lr)\n",
        "                    \n",
        "                    if j==len(X_train)-1:\n",
        "                        ss.append(loss)\n",
        "            if gradient_descent_method=='mini_batch':\n",
        "                loss=0\n",
        "                for j in range (0,len(X_train)//batch_size):\n",
        "                    samples=[]\n",
        "                    labels=[]\n",
        "                    for k in range (0,batch_size):\n",
        "                        samples.append(X_train[batch_size*j+k])\n",
        "                        labels.append(Y_train[batch_size*j+k])\n",
        "                    y_pred=self.predict(samples)\n",
        "                    loss=self.loss.forward(y_pred,labels)\n",
        "                    # print(loss)\n",
        "                    computed_loss=self.loss.backward()\n",
        "                    computed_loss=np.array(computed_loss)\n",
        "                    computed_loss=np.mean(computed_loss)\n",
        "                    # print(computed_loss)\n",
        "                    self.backward(computed_loss)\n",
        "\n",
        "                    self.update_parameters(learning_rate)\n",
        "                ss.append(loss)\n",
        "\n",
        "\n",
        "            learning_rate = learning_rate_sch.update_learning_rate(current_epoch=i + 1)\n",
        "            \n",
        "\n",
        "        return ss\n",
        "    def check_early_stopping(self,loss):\n",
        "        if len(loss)>2:\n",
        "            if loss[-2]<loss[-1]:\n",
        "                self.stop_count+=1\n",
        "            else:\n",
        "                self.stop_count=0\n",
        "        if self.stop_count>10:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def dropout(self):\n",
        "        for i in range(0,len(self.parameters)):\n",
        "            for j in range(0,(self.parameters[i]['weights'].shape[0])):\n",
        "                for k in range(0,(self.parameters[i]['weights'].shape[1])):\n",
        "                \n",
        "                    if np.random.randn(0,5)<0.2:\n",
        "                        self.parameters[i]['weights'][j][k]=0\n",
        "                if np.random.randn(0,5)<0.2:\n",
        "                    self.parameters[i]['biases'][j]=0\n",
        "\n",
        "        \n",
        "        pass\n",
        "    def update_parameters(self,learning_rate):\n",
        "        parameters=[]\n",
        "        for i in range(0,len(self.parameters)):\n",
        "            #print(f\"old weights = {self.parameters[i]['weights'][0]}]\")\n",
        "            w=self.parameters[i]['weights']-learning_rate*self.weightsgrads[len(self.parameters)-i-1]\n",
        "            print(f\"new weights of layer {i+1} = {w[0]}\")\n",
        "\n",
        "            # print(\"output\",self.parameters[i]['weights'].shape)\n",
        "            s=np.array(self.biasgrads[len(self.parameters)-i-1])\n",
        "            b=self.parameters[i]['biases']-learning_rate*s\n",
        "            layer_param = {'weights': w, 'biases': b}\n",
        "            parameters.append(layer_param)\n",
        "        self.parameters=parameters\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred=[]\n",
        "        for i in range(0,len(X)):\n",
        "            y=self.forward(X[i])\n",
        "            y_pred.append(y)\n",
        "        y_pred=np.array(y_pred)\n",
        "        return (y_pred)\n",
        "\n",
        "    def score(self, X, y_true):\n",
        "      y_pred = self.predict(X)\n",
        "\n",
        "      if self.activFunc[-1] == 'sigmoid' or self.activFunc[-1] == 'softmax':  # If problem is classification\n",
        "        accuracy = accuracy_score(y_true, y_pred)\n",
        "        return accuracy\n",
        "      else:  # If problem is regression\n",
        "        mse = mean_squared_error(y_true, y_pred)\n",
        "        return mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut350xMRLfyh"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "c4eK_aUxLhd2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "dataset=pd.read_csv(\"training_data.csv\")\n",
        "start = 0\n",
        "end = 2\n",
        "X = dataset.iloc[start:end, -3:-1].values\n",
        "y = dataset.iloc[start:end, -1].values\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X = min_max_scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "X_test = [\n",
        "    [0, 0],\n",
        "    [120, 1],\n",
        "    [130, 1],\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "xplot=[]\n",
        "for i in range(0,len(losses)):\n",
        "    xplot.append(i+1)\n",
        "xplot=np.array(xplot)\n",
        "plt.plot(xplot, losses)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ktdVeWRr0cE",
        "outputId": "8f616a3b-a465-4ea8-d1e5-2dfccfd57692"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvND-k_foGf_",
        "outputId": "b13df161-c930-49fa-9c0a-26e5e7581f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "self.sig = [0.99999834]\n",
            "self.sig = [1.]\n",
            "self.sig = [1.]\n",
            "[[0.99999834]\n",
            " [1.        ]\n",
            " [1.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(k.predict(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF-2uZaA3hdM"
      },
      "source": [
        "#Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "MOXqJlv03hBN",
        "outputId": "7f44eb7f-d46c-4caa-ad4e-3c0e5682ae75"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "the number of layers is not equal to the number of activation funcs",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[149], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m   fun\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# activation functions of hidden layers\u001b[39;00m\n\u001b[0;32m     26\u001b[0m fun\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# activation function of output layer\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mmy_Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m k\u001b[38;5;241m.\u001b[39mtrain(X,y,num_epochs\u001b[38;5;241m=\u001b[39mnumber_of_epochs,learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m     30\u001b[0m score \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n",
            "Cell \u001b[1;32mIn[142], line 11\u001b[0m, in \u001b[0;36mmy_Model.__init__\u001b[1;34m(self, layers_dim, actiation_func, loss)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiasgrads\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layers_dim)\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mlen\u001b[39m(actiation_func)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of layers is not equal to the number of activation funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     13\u001b[0m   layer\u001b[38;5;241m=\u001b[39m[]\n",
            "\u001b[1;31mValueError\u001b[0m: the number of layers is not equal to the number of activation funcs"
          ]
        }
      ],
      "source": [
        "parameters_grid = {\n",
        "    'learning_rate': [1, 0.1, 0.01],\n",
        "    'batch_size': [16, 32, 64, 128],\n",
        "    'loss': ['CE', 'L2'],\n",
        "    'number_of_hidden_layers': [1, 2, 3],\n",
        "    'number_of_neurons_per_hidden_layer': [2, 3, 5, 10],\n",
        "    'epochs': [10, 50, 100]\n",
        "}\n",
        "\n",
        "max_score = 0\n",
        "preferred_parameters = {}\n",
        "\n",
        "for learning_rate in parameters_grid['learning_rate']:\n",
        "  for batch_size in range(len(parameters_grid['batch_size'])):\n",
        "    for loss in range(len(parameters_grid['loss'])):\n",
        "      for number_of_hidden_layers in parameters_grid['number_of_hidden_layers']:\n",
        "        for number_of_neurons in parameters_grid['number_of_neurons_per_hidden_layer']:\n",
        "          for number_of_epochs in parameters_grid['number_of_neurons_per_hidden_layer']:\n",
        "\n",
        "            dim = [len(X[0])]\n",
        "            fun = []\n",
        "\n",
        "            for a in range(number_of_hidden_layers):\n",
        "              dim.append(number_of_neurons)\n",
        "              fun.append('relu') # activation functions of hidden layers\n",
        "            fun.append('sigmoid') # activation function of output layer\n",
        "\n",
        "            network = my_Model(dim,fun,loss)\n",
        "            k.train(X,y,num_epochs=number_of_epochs,learning_rate=learning_rate, batch_size=batch_size)\n",
        "            score = k.score(X_test, y_test)\n",
        "\n",
        "            if score > max_score:\n",
        "                max_score = score\n",
        "                preferred_parameters = {\n",
        "                  'learning_rate': learning_rate,\n",
        "                  'batch_size': batch_size,\n",
        "                  'loss': loss,\n",
        "                  'number_of_hidden_layers': number_of_hidden_layers,\n",
        "                  'number_of_neurons_per_hidden_layer': number_of_neurons,\n",
        "                  'epochs':number_of_epochs,\n",
        "                }\n",
        "\n",
        "print(f\"Max score of {max_score} achieved at parameters: {preferred_parameters}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-jxkO7LFkf2"
      },
      "source": [
        "#Learning Rate Scheduling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR3eq1qKFjxY"
      },
      "outputs": [],
      "source": [
        "class LearningRateScheduler:\n",
        "  def __init__(self, decay_type, learning_rate, total_epochs):\n",
        "    self.decay_type = decay_type\n",
        "    self.learning_rate = learning_rate\n",
        "    self.total_epochs = total_epochs\n",
        "\n",
        "  def update_learning_rate(self, current_epoch):\n",
        "    if self.decay_type == 'cosine':\n",
        "      new_learning_rate = 0.5 * self.learning_rate * (1 + np.cos((current_epoch * np.pi) / self.total_epochs))\n",
        "    elif self.decay_type == 'linear':\n",
        "      new_learning_rate = self.learning_rate * (1 - (current_epoch / self.total_epochs))\n",
        "    elif self.decay_type == 'inverse sqrt':\n",
        "      new_learning_rate = self.learning_rate / np.sqrt(current_epoch)\n",
        "\n",
        "    return new_learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "JCrXyxcJRmwh",
        "outputId": "f1c4e868-57c9-46b2-d1ae-e00c7a6bf5d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
